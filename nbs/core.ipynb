{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de8bcd7",
   "metadata": {},
   "source": [
    "# Core Data Structures\n",
    "\n",
    "> DTOs for audio transcription with FileBackedDTO support for zero-copy transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import tempfile\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "from cjm_plugin_system.core.interface import FileBackedDTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9970cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class AudioData:\n",
    "    \"\"\"\n",
    "    Container for raw audio data.\n",
    "    Implements FileBackedDTO for zero-copy transfer between Host and Worker processes.\n",
    "    \"\"\"\n",
    "    samples: np.ndarray  # Audio sample data as numpy array\n",
    "    sample_rate: int     # Sample rate in Hz (e.g., 16000, 44100)\n",
    "\n",
    "    def to_temp_file(self) -> str: # Absolute path to temporary WAV file\n",
    "        \"\"\"Save audio to a temp file for zero-copy transfer to Worker process.\"\"\"\n",
    "        # Create temp file (delete=False so Worker can read it)\n",
    "        tmp = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "        \n",
    "        # Ensure float32 format\n",
    "        audio = self.samples\n",
    "        if audio.dtype != np.float32:\n",
    "            audio = audio.astype(np.float32)\n",
    "        \n",
    "        # Normalize if needed\n",
    "        max_val = np.abs(audio).max()\n",
    "        if max_val > 1.0:\n",
    "            audio = audio / max_val\n",
    "        \n",
    "        # Write to disk\n",
    "        sf.write(tmp.name, audio, self.sample_rate)\n",
    "        tmp.close()\n",
    "        \n",
    "        return str(Path(tmp.name).absolute())\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]: # Serialized representation\n",
    "        \"\"\"Convert to dictionary for smaller payloads.\"\"\"\n",
    "        return {\n",
    "            \"samples\": self.samples.tolist(),\n",
    "            \"sample_rate\": self.sample_rate\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(\n",
    "        cls,\n",
    "        filepath: str # Path to audio file\n",
    "    ) -> \"AudioData\": # AudioData instance\n",
    "        \"\"\"Load audio from a file.\"\"\"\n",
    "        samples, sample_rate = sf.read(filepath, dtype='float32')\n",
    "        return cls(samples=samples, sample_rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c53ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class TranscriptionResult:\n",
    "    \"\"\"Standardized output for all transcription plugins.\"\"\"\n",
    "    text: str                                        # The transcribed text\n",
    "    confidence: Optional[float] = None               # Overall confidence (0.0 to 1.0)\n",
    "    segments: Optional[List[Dict[str, Any]]] = None  # Timestamped segments\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)  # Additional metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5813562",
   "metadata": {},
   "source": [
    "## Testing AudioData\n",
    "\n",
    "AudioData implements the `FileBackedDTO` protocol, which means the `RemotePluginProxy` will automatically serialize it to a temp file before sending to the Worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc4fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudioData: 16000 samples at 16000Hz\n",
      "\n",
      "Implements FileBackedDTO: True\n",
      "Saved to temp file: /tmp/tmpbpdzmhhx.wav\n",
      "File exists: True\n",
      "File size: 32044 bytes\n"
     ]
    }
   ],
   "source": [
    "# Test AudioData creation\n",
    "audio = AudioData(\n",
    "    samples=np.sin(np.linspace(0, 2*np.pi*440, 16000)),  # 1 second of 440Hz tone\n",
    "    sample_rate=16000\n",
    ")\n",
    "\n",
    "print(f\"AudioData: {len(audio.samples)} samples at {audio.sample_rate}Hz\")\n",
    "\n",
    "# Test FileBackedDTO protocol\n",
    "print(f\"\\nImplements FileBackedDTO: {isinstance(audio, FileBackedDTO)}\")\n",
    "\n",
    "# Test to_temp_file (this is what the Proxy calls)\n",
    "temp_path = audio.to_temp_file()\n",
    "print(f\"Saved to temp file: {temp_path}\")\n",
    "\n",
    "# Verify the file exists and can be read back\n",
    "import os\n",
    "print(f\"File exists: {os.path.exists(temp_path)}\")\n",
    "print(f\"File size: {os.path.getsize(temp_path)} bytes\")\n",
    "\n",
    "# Clean up\n",
    "os.unlink(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6930b22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Hello world\n",
      "Confidence: 0.95\n",
      "Segments: [{'start': 0.0, 'end': 0.5, 'text': 'Hello'}, {'start': 0.5, 'end': 1.0, 'text': 'world'}]\n",
      "Metadata: {'model': 'whisper-large-v3', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "# Test TranscriptionResult\n",
    "result = TranscriptionResult(\n",
    "    text=\"Hello world\",\n",
    "    confidence=0.95,\n",
    "    segments=[\n",
    "        {\"start\": 0.0, \"end\": 0.5, \"text\": \"Hello\"},\n",
    "        {\"start\": 0.5, \"end\": 1.0, \"text\": \"world\"}\n",
    "    ],\n",
    "    metadata={\"model\": \"whisper-large-v3\", \"language\": \"en\"}\n",
    ")\n",
    "\n",
    "print(f\"Text: {result.text}\")\n",
    "print(f\"Confidence: {result.confidence}\")\n",
    "print(f\"Segments: {result.segments}\")\n",
    "print(f\"Metadata: {result.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb489b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal result: TranscriptionResult(text='Just the text', confidence=None, segments=None, metadata={})\n"
     ]
    }
   ],
   "source": [
    "# Test minimal result (only text required)\n",
    "minimal = TranscriptionResult(text=\"Just the text\")\n",
    "print(f\"Minimal result: {minimal}\")\n",
    "\n",
    "# Test from_file class method (if audio file available)\n",
    "# audio_loaded = AudioData.from_file(\"path/to/audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca55802a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ecc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
