{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": [
    "# Transcription Storage\n",
    "\n",
    "> Standardized SQLite storage for transcription results with content hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-default-exp",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-showdoc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "import sqlite3\n",
    "import time\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from cjm_plugin_system.utils.hashing import hash_bytes, hash_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-schema-docs",
   "metadata": {},
   "source": [
    "## TranscriptionRow\n",
    "\n",
    "A dataclass representing a single row in the standardized transcriptions table. This provides a type-safe way to work with stored transcription results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-row-dataclass",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class TranscriptionRow:\n",
    "    \"\"\"A single row from the transcriptions table.\"\"\"\n",
    "    job_id: str          # Unique job identifier\n",
    "    audio_path: str      # Path to the source audio file\n",
    "    audio_hash: str      # Hash of source audio in \"algo:hexdigest\" format\n",
    "    text: str            # Transcribed text output\n",
    "    text_hash: str       # Hash of transcribed text in \"algo:hexdigest\" format\n",
    "    segments: Optional[List[Dict[str, Any]]] = None  # Timestamped segments\n",
    "    metadata: Optional[Dict[str, Any]] = None        # Plugin metadata\n",
    "    created_at: Optional[float] = None               # Unix timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-test-row",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: job_id=job_abc123, text=Hello world...\n",
      "Audio hash: sha256:aaaaaaaaaaaaa...\n",
      "Text hash: sha256:bbbbbbbbbbbbb...\n"
     ]
    }
   ],
   "source": [
    "# Test TranscriptionRow creation\n",
    "row = TranscriptionRow(\n",
    "    job_id=\"job_abc123\",\n",
    "    audio_path=\"/tmp/test.mp3\",\n",
    "    audio_hash=\"sha256:\" + \"a\" * 64,\n",
    "    text=\"Hello world\",\n",
    "    text_hash=\"sha256:\" + \"b\" * 64,\n",
    "    segments=[{\"start\": 0.0, \"end\": 1.0, \"text\": \"Hello world\"}],\n",
    "    metadata={\"model\": \"whisper-large-v3\"}\n",
    ")\n",
    "\n",
    "print(f\"Row: job_id={row.job_id}, text={row.text[:20]}...\")\n",
    "print(f\"Audio hash: {row.audio_hash[:20]}...\")\n",
    "print(f\"Text hash: {row.text_hash[:20]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-storage-docs",
   "metadata": {},
   "source": [
    "## TranscriptionStorage\n",
    "\n",
    "Standardized SQLite storage that all transcription plugins should use. Defines the canonical schema for the `transcriptions` table with content hash columns for traceability.\n",
    "\n",
    "**Schema:**\n",
    "\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS transcriptions (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    job_id TEXT UNIQUE NOT NULL,\n",
    "    audio_path TEXT NOT NULL,\n",
    "    audio_hash TEXT NOT NULL,\n",
    "    text TEXT NOT NULL,\n",
    "    text_hash TEXT NOT NULL,\n",
    "    segments JSON,\n",
    "    metadata JSON,\n",
    "    created_at REAL NOT NULL\n",
    ");\n",
    "```\n",
    "\n",
    "The `audio_hash` and `text_hash` columns use the self-describing `\"algo:hexdigest\"` format (e.g., `\"sha256:a3f2b8...\"`), enabling downstream consumers to verify content integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-storage-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TranscriptionStorage:\n",
    "    \"\"\"Standardized SQLite storage for transcription results.\"\"\"\n",
    "\n",
    "    SCHEMA = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS transcriptions (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            job_id TEXT UNIQUE NOT NULL,\n",
    "            audio_path TEXT NOT NULL,\n",
    "            audio_hash TEXT NOT NULL,\n",
    "            text TEXT NOT NULL,\n",
    "            text_hash TEXT NOT NULL,\n",
    "            segments JSON,\n",
    "            metadata JSON,\n",
    "            created_at REAL NOT NULL\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    INDEX = \"CREATE INDEX IF NOT EXISTS idx_transcriptions_job_id ON transcriptions(job_id);\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        db_path: str  # Absolute path to the SQLite database file\n",
    "    ):\n",
    "        \"\"\"Initialize storage and create table if needed.\"\"\"\n",
    "        self.db_path = db_path\n",
    "        with sqlite3.connect(self.db_path) as con:\n",
    "            con.execute(self.SCHEMA)\n",
    "            con.execute(self.INDEX)\n",
    "\n",
    "    def save(\n",
    "        self,\n",
    "        job_id: str,        # Unique job identifier\n",
    "        audio_path: str,    # Path to the source audio file\n",
    "        audio_hash: str,    # Hash of source audio in \"algo:hexdigest\" format\n",
    "        text: str,          # Transcribed text output\n",
    "        text_hash: str,     # Hash of transcribed text in \"algo:hexdigest\" format\n",
    "        segments: Optional[List[Dict[str, Any]]] = None,  # Timestamped segments\n",
    "        metadata: Optional[Dict[str, Any]] = None         # Plugin metadata\n",
    "    ) -> None:\n",
    "        \"\"\"Save a transcription result to the database.\"\"\"\n",
    "        with sqlite3.connect(self.db_path) as con:\n",
    "            con.execute(\n",
    "                \"\"\"INSERT INTO transcriptions\n",
    "                   (job_id, audio_path, audio_hash, text, text_hash, segments, metadata, created_at)\n",
    "                   VALUES (?, ?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "                (\n",
    "                    job_id,\n",
    "                    audio_path,\n",
    "                    audio_hash,\n",
    "                    text,\n",
    "                    text_hash,\n",
    "                    json.dumps(segments) if segments else None,\n",
    "                    json.dumps(metadata) if metadata else None,\n",
    "                    time.time()\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def get_by_job_id(\n",
    "        self,\n",
    "        job_id: str  # Job identifier to look up\n",
    "    ) -> Optional[TranscriptionRow]:  # Row or None if not found\n",
    "        \"\"\"Retrieve a transcription result by job ID.\"\"\"\n",
    "        with sqlite3.connect(self.db_path) as con:\n",
    "            cur = con.execute(\n",
    "                \"\"\"SELECT job_id, audio_path, audio_hash, text, text_hash,\n",
    "                          segments, metadata, created_at\n",
    "                   FROM transcriptions WHERE job_id = ?\"\"\",\n",
    "                (job_id,)\n",
    "            )\n",
    "            row = cur.fetchone()\n",
    "            if not row:\n",
    "                return None\n",
    "            return TranscriptionRow(\n",
    "                job_id=row[0],\n",
    "                audio_path=row[1],\n",
    "                audio_hash=row[2],\n",
    "                text=row[3],\n",
    "                text_hash=row[4],\n",
    "                segments=json.loads(row[5]) if row[5] else None,\n",
    "                metadata=json.loads(row[6]) if row[6] else None,\n",
    "                created_at=row[7]\n",
    "            )\n",
    "\n",
    "    def list_jobs(\n",
    "        self,\n",
    "        limit: int = 100  # Maximum number of rows to return\n",
    "    ) -> List[TranscriptionRow]:  # List of transcription rows\n",
    "        \"\"\"List transcription jobs ordered by creation time (newest first).\"\"\"\n",
    "        results = []\n",
    "        with sqlite3.connect(self.db_path) as con:\n",
    "            cur = con.execute(\n",
    "                \"\"\"SELECT job_id, audio_path, audio_hash, text, text_hash,\n",
    "                          segments, metadata, created_at\n",
    "                   FROM transcriptions ORDER BY created_at DESC LIMIT ?\"\"\",\n",
    "                (limit,)\n",
    "            )\n",
    "            for row in cur:\n",
    "                results.append(TranscriptionRow(\n",
    "                    job_id=row[0],\n",
    "                    audio_path=row[1],\n",
    "                    audio_hash=row[2],\n",
    "                    text=row[3],\n",
    "                    text_hash=row[4],\n",
    "                    segments=json.loads(row[5]) if row[5] else None,\n",
    "                    metadata=json.loads(row[6]) if row[6] else None,\n",
    "                    created_at=row[7]\n",
    "                ))\n",
    "        return results\n",
    "\n",
    "    def verify_audio(\n",
    "        self,\n",
    "        job_id: str  # Job identifier to verify\n",
    "    ) -> Optional[bool]:  # True if audio matches, False if tampered, None if job not found\n",
    "        \"\"\"Verify the source audio file still matches its stored hash.\"\"\"\n",
    "        row = self.get_by_job_id(job_id)\n",
    "        if not row:\n",
    "            return None\n",
    "        current_hash = hash_file(row.audio_path)\n",
    "        return current_hash == row.audio_hash\n",
    "\n",
    "    def verify_text(\n",
    "        self,\n",
    "        job_id: str  # Job identifier to verify\n",
    "    ) -> Optional[bool]:  # True if text matches, False if tampered, None if job not found\n",
    "        \"\"\"Verify the transcription text still matches its stored hash.\"\"\"\n",
    "        row = self.get_by_job_id(job_id)\n",
    "        if not row:\n",
    "            return None\n",
    "        current_hash = hash_bytes(row.text.encode())\n",
    "        return current_hash == row.text_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-testing-header",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-test-storage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage initialized at: /tmp/tmp3eoimb1w.db\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Create storage with temp database\n",
    "tmp_db = tempfile.NamedTemporaryFile(suffix=\".db\", delete=False)\n",
    "storage = TranscriptionStorage(tmp_db.name)\n",
    "\n",
    "print(f\"Storage initialized at: {tmp_db.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-test-save",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved job_test_001\n",
      "Text hash: sha256:83efd1674de9fcf20e5c2edacf9246f7f34ad04bf07ddcb2b4e2765269e1edd1\n"
     ]
    }
   ],
   "source": [
    "# Save a transcription result with hashes\n",
    "test_text = \"Laying Plans Sun Tzu said, The art of war is of vital importance to the state.\"\n",
    "text_hash = hash_bytes(test_text.encode())\n",
    "audio_hash = \"sha256:\" + \"e3b0c44298\" * 6 + \"e3b0\"  # Simulated audio hash\n",
    "\n",
    "storage.save(\n",
    "    job_id=\"job_test_001\",\n",
    "    audio_path=\"/tmp/test_audio.mp3\",\n",
    "    audio_hash=audio_hash,\n",
    "    text=test_text,\n",
    "    text_hash=text_hash,\n",
    "    segments=[{\"start\": 0.0, \"end\": 5.0, \"text\": test_text}],\n",
    "    metadata={\"model\": \"whisper-large-v3\", \"language\": \"en\"}\n",
    ")\n",
    "\n",
    "print(f\"Saved job_test_001\")\n",
    "print(f\"Text hash: {text_hash}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-test-retrieve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved: job_test_001\n",
      "Text: Laying Plans Sun Tzu said, The art of wa...\n",
      "Audio hash: sha256:e3b0c44298e3b0c44298e3b...\n",
      "Text hash: sha256:83efd1674de9fcf20e5c2ed...\n",
      "Created at: 1770425259.7641876\n"
     ]
    }
   ],
   "source": [
    "# Retrieve by job ID\n",
    "row = storage.get_by_job_id(\"job_test_001\")\n",
    "assert row is not None\n",
    "assert row.job_id == \"job_test_001\"\n",
    "assert row.text == test_text\n",
    "assert row.text_hash == text_hash\n",
    "assert row.audio_hash == audio_hash\n",
    "assert row.segments is not None\n",
    "assert row.metadata[\"model\"] == \"whisper-large-v3\"\n",
    "assert row.created_at is not None\n",
    "\n",
    "print(f\"Retrieved: {row.job_id}\")\n",
    "print(f\"Text: {row.text[:40]}...\")\n",
    "print(f\"Audio hash: {row.audio_hash[:30]}...\")\n",
    "print(f\"Text hash: {row.text_hash[:30]}...\")\n",
    "print(f\"Created at: {row.created_at}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-test-missing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_by_job_id returns None for missing job: OK\n"
     ]
    }
   ],
   "source": [
    "# Missing job returns None\n",
    "missing = storage.get_by_job_id(\"nonexistent\")\n",
    "assert missing is None\n",
    "print(\"get_by_job_id returns None for missing job: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-test-list",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_jobs returned 2 rows (newest first): ['job_test_002', 'job_test_001']\n"
     ]
    }
   ],
   "source": [
    "# Save another and test list_jobs\n",
    "storage.save(\n",
    "    job_id=\"job_test_002\",\n",
    "    audio_path=\"/tmp/test_audio_2.mp3\",\n",
    "    audio_hash=\"sha256:\" + \"f\" * 64,\n",
    "    text=\"Second transcription.\",\n",
    "    text_hash=hash_bytes(b\"Second transcription.\")\n",
    ")\n",
    "\n",
    "jobs = storage.list_jobs()\n",
    "assert len(jobs) == 2\n",
    "# Newest first\n",
    "assert jobs[0].job_id == \"job_test_002\"\n",
    "assert jobs[1].job_id == \"job_test_001\"\n",
    "\n",
    "print(f\"list_jobs returned {len(jobs)} rows (newest first): {[j.job_id for j in jobs]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-test-verify-text",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verify_text with unchanged text: True\n",
      "verify_text after tampering: False\n",
      "verify_text for missing job: None\n"
     ]
    }
   ],
   "source": [
    "# Test text verification\n",
    "assert storage.verify_text(\"job_test_001\") == True\n",
    "print(\"verify_text with unchanged text: True\")\n",
    "\n",
    "# Tamper with text directly in DB\n",
    "with sqlite3.connect(tmp_db.name) as con:\n",
    "    con.execute(\"UPDATE transcriptions SET text = 'TAMPERED' WHERE job_id = 'job_test_001'\")\n",
    "\n",
    "assert storage.verify_text(\"job_test_001\") == False\n",
    "print(\"verify_text after tampering: False\")\n",
    "\n",
    "# Missing job returns None\n",
    "assert storage.verify_text(\"nonexistent\") is None\n",
    "print(\"verify_text for missing job: None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-test-cleanup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanup complete\n"
     ]
    }
   ],
   "source": [
    "# Cleanup\n",
    "os.unlink(tmp_db.name)\n",
    "print(\"Cleanup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-nbdev-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
