{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription Plugin Interface\n",
    "\n",
    "> Domain-specific plugin interface for audio transcription plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp plugin_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "import logging\n",
    "from typing import Optional, Dict, Any, Union, List, Tuple, Generator, Type\n",
    "from pathlib import Path\n",
    "\n",
    "# Import generic plugin infrastructure from cjm-plugin-system\n",
    "from cjm_plugin_system.core.interface import PluginInterface\n",
    "from cjm_plugin_system.core.metadata import PluginMeta\n",
    "from cjm_plugin_system.utils.validation import (\n",
    "    dict_to_config, config_to_dict, validate_config,\n",
    "    SCHEMA_TITLE, SCHEMA_DESC, SCHEMA_MIN, SCHEMA_MAX, SCHEMA_ENUM\n",
    ")\n",
    "\n",
    "# Import domain-specific types\n",
    "from cjm_transcription_plugin_system.core import AudioData, TranscriptionResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TranscriptionPlugin(PluginInterface):\n",
    "    \"\"\"Transcription-specific plugin interface.\n",
    "    \n",
    "    This extends the generic PluginInterface with transcription-specific\n",
    "    requirements like supported audio formats and the execute signature.\n",
    "    \n",
    "    All transcription plugins must implement this interface.\n",
    "    \"\"\"\n",
    "\n",
    "    entry_point_group = \"transcription.plugins\"\n",
    "    \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def supported_formats(\n",
    "        self\n",
    "    ) -> List[str]:  # List of file extensions without the dot (e.g., ['wav', 'mp3', 'flac'])\n",
    "        \"\"\"List of supported audio formats.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def execute(\n",
    "        self,\n",
    "        audio: Union[AudioData, str, Path],  # Audio data (AudioData object), file path (str), or Path object\n",
    "        **kwargs  # Additional plugin-specific parameters (e.g., language, model)\n",
    "    ) -> TranscriptionResult:  # Transcription result with text, confidence, segments, and metadata\n",
    "        \"\"\"Transcribe audio to text.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TranscriptionPlugin Interface\n",
    "\n",
    "The `TranscriptionPlugin` interface extends the generic `PluginInterface` from `cjm-plugin-system` with transcription-specific requirements:\n",
    "\n",
    "- **`supported_formats`** property: List of audio file formats this plugin can handle\n",
    "- **`execute`** method signature: Takes audio input and returns `TranscriptionResult`\n",
    "\n",
    "All generic plugin functionality (dataclass-based configuration, validation, streaming support, etc.) is inherited from the base `PluginInterface` class.\n",
    "\n",
    "Plugins define their configuration using dataclasses with field metadata for validation constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PluginMeta instance:\n",
      "PluginMeta(name='test_plugin', version='1.0.0', description='A test plugin', author='Test Author', package_name='', instance=None, enabled=True)\n",
      "\n",
      "Name: test_plugin\n",
      "Version: 1.0.0\n",
      "Enabled: True\n",
      "Instance: None\n",
      "\n",
      "Minimal PluginMeta: PluginMeta(name='minimal', version='0.1.0', description='', author='', package_name='', instance=None, enabled=True)\n",
      "Equality test: True\n"
     ]
    }
   ],
   "source": [
    "# Test PluginMeta dataclass\n",
    "meta = PluginMeta(\n",
    "    name=\"test_plugin\",\n",
    "    version=\"1.0.0\",\n",
    "    description=\"A test plugin\",\n",
    "    author=\"Test Author\"\n",
    ")\n",
    "\n",
    "print(\"PluginMeta instance:\")\n",
    "print(meta)\n",
    "print(f\"\\nName: {meta.name}\")\n",
    "print(f\"Version: {meta.version}\")\n",
    "print(f\"Enabled: {meta.enabled}\")\n",
    "print(f\"Instance: {meta.instance}\")\n",
    "\n",
    "# Test with minimal arguments\n",
    "minimal_meta = PluginMeta(name=\"minimal\", version=\"0.1.0\")\n",
    "print(f\"\\nMinimal PluginMeta: {minimal_meta}\")\n",
    "\n",
    "# Test equality\n",
    "meta_copy = PluginMeta(name=\"minimal\", version=\"0.1.0\")\n",
    "print(f\"Equality test: {minimal_meta == meta_copy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ExamplePlugin\n",
    "\n",
    "Let's test a simple transcription plugin implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configuration dataclass for the example plugin\n",
    "@dataclass\n",
    "class ExamplePluginConfig:\n",
    "    \"\"\"Configuration for ExamplePlugin.\"\"\"\n",
    "    model:str = field(\n",
    "        default=\"base\",\n",
    "        metadata={\n",
    "            SCHEMA_TITLE: \"Model\",\n",
    "            SCHEMA_DESC: \"Model size to use for transcription\",\n",
    "            SCHEMA_ENUM: [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
    "        }\n",
    "    )\n",
    "    language:str = field(\n",
    "        default=\"auto\",\n",
    "        metadata={\n",
    "            SCHEMA_TITLE: \"Language\",\n",
    "            SCHEMA_DESC: \"Language code (e.g., 'en', 'es') or 'auto' for detection\"\n",
    "        }\n",
    "    )\n",
    "    batch_size:int = field(\n",
    "        default=8,\n",
    "        metadata={\n",
    "            SCHEMA_TITLE: \"Batch Size\",\n",
    "            SCHEMA_DESC: \"Batch size for processing\",\n",
    "            SCHEMA_MIN: 1,\n",
    "            SCHEMA_MAX: 32\n",
    "        }\n",
    "    )\n",
    "    enable_vad:bool = field(\n",
    "        default=True,\n",
    "        metadata={\n",
    "            SCHEMA_TITLE: \"Enable VAD\",\n",
    "            SCHEMA_DESC: \"Enable voice activity detection\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "class ExamplePlugin(TranscriptionPlugin):\n",
    "    \"\"\"An example transcription plugin implementation with dataclass configuration.\"\"\"\n",
    "    \n",
    "    config_class = ExamplePluginConfig\n",
    "\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{type(self).__name__}\")\n",
    "        self.config: ExamplePluginConfig = None\n",
    "        self.model = None\n",
    "    \n",
    "    @property\n",
    "    def name(self) -> str: # Plugin name identifier\n",
    "        return \"example_plugin\"\n",
    "    \n",
    "    @property\n",
    "    def version(self) -> str: # Plugin version string\n",
    "        return \"1.0.0\"\n",
    "\n",
    "    @property\n",
    "    def supported_formats(self) -> List[str]: # List of supported audio file extensions\n",
    "        return [\"wav\", \"mp3\", \"flac\"]\n",
    "    \n",
    "    def get_current_config(self) -> ExamplePluginConfig: # Current configuration dataclass\n",
    "        \"\"\"Return the current configuration.\"\"\"\n",
    "        return self.config\n",
    "    \n",
    "    def initialize(\n",
    "        self, \n",
    "        config: Optional[Any] = None # Configuration dataclass, dict, or None\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the plugin.\"\"\"\n",
    "        if config is None:\n",
    "            self.config = ExamplePluginConfig()\n",
    "        elif isinstance(config, ExamplePluginConfig):\n",
    "            self.config = config\n",
    "        elif isinstance(config, dict):\n",
    "            self.config = dict_to_config(ExamplePluginConfig, config, validate=True)\n",
    "        else:\n",
    "            raise TypeError(f\"Expected ExamplePluginConfig, dict, or None, got {type(config).__name__}\")\n",
    "        \n",
    "        self.logger.info(f\"Initializing {self.name} with config: {self.config}\")\n",
    "        \n",
    "        # Simulate loading a model based on config\n",
    "        self.model = f\"MockModel-{self.config.model}\"\n",
    "    \n",
    "    def execute(\n",
    "        self,\n",
    "        audio: Union[AudioData, str, Path], # Audio data or path to audio file\n",
    "        **kwargs # Additional plugin-specific parameters\n",
    "    ) -> TranscriptionResult: # Transcription result with text and metadata\n",
    "        \"\"\"Execute the plugin's functionality.\"\"\"\n",
    "        self.logger.info(f\"Example plugin executed with model: {self.model}\")\n",
    "        self.logger.info(f\"Config: {self.config}\")\n",
    "        \n",
    "        # Mock transcription result\n",
    "        return TranscriptionResult(\n",
    "            text=f\"Transcription using {self.model}\",\n",
    "            confidence=0.95,\n",
    "            segments=[],\n",
    "            metadata={\"model\": self.config.model}\n",
    "        )\n",
    "\n",
    "    def is_available(self) -> bool: # True if plugin dependencies are available\n",
    "        \"\"\"Check availability.\"\"\"\n",
    "        return True\n",
    "    \n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        self.logger.info(f\"Cleaning up {self.name}\")\n",
    "        self.model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__.ExamplePlugin:Initializing example_plugin with config: ExamplePluginConfig(model='base', language='auto', batch_size=8, enable_vad=True)\n",
      "INFO:__main__.ExamplePlugin:Example plugin executed with model: MockModel-base\n",
      "INFO:__main__.ExamplePlugin:Config: ExamplePluginConfig(model='base', language='auto', batch_size=8, enable_vad=True)\n",
      "INFO:__main__.ExamplePlugin:Cleaning up example_plugin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result text: Transcription using MockModel-base\n",
      "Result confidence: 0.95\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "example_plugin = ExamplePlugin()\n",
    "example_plugin.initialize()\n",
    "transcription_result = example_plugin.execute(\"test_audio.mp3\")\n",
    "example_plugin.cleanup()\n",
    "print(f\"Result text: {transcription_result.text}\")\n",
    "print(f\"Result confidence: {transcription_result.confidence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__.ExamplePlugin:Initializing example_plugin with config: ExamplePluginConfig(model='small', language='en', batch_size=8, enable_vad=True)\n",
      "INFO:__main__.ExamplePlugin:Initializing example_plugin with config: ExamplePluginConfig(model='tiny', language='auto', batch_size=8, enable_vad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Class: ExamplePluginConfig\n",
      "\n",
      "Default Configuration:\n",
      "  model: 'base'\n",
      "  language: 'auto'\n",
      "  batch_size: 8\n",
      "  enable_vad: True\n",
      "\n",
      "==================================================\n",
      "\n",
      "Current Configuration after initialization:\n",
      "  model: small\n",
      "  language: en\n",
      "  batch_size: 8\n",
      "  enable_vad: True\n",
      "\n",
      "==================================================\n",
      "\n",
      "Configuration Validation Tests:\n",
      "✓ Valid config with model='tiny' accepted\n",
      "✓ Invalid model rejected: model: 'invalid_model' is not one of ['tiny', 'base', 'small', 'medium', 'large']\n",
      "✓ Batch size > max rejected: batch_size: 100 is greater than maximum 32\n"
     ]
    }
   ],
   "source": [
    "# Test the dataclass configuration functionality\n",
    "plugin = ExamplePlugin()\n",
    "\n",
    "# Get the configuration class\n",
    "print(\"Configuration Class:\", plugin.config_class.__name__)\n",
    "\n",
    "# Get default configuration\n",
    "defaults = plugin.get_config_defaults()\n",
    "print(\"\\nDefault Configuration:\")\n",
    "for k, v in defaults.items():\n",
    "    print(f\"  {k}: {v!r}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Initialize with partial config (using defaults for missing values)\n",
    "plugin.initialize({\"model\": \"small\", \"language\": \"en\"})\n",
    "current = plugin.get_current_config()\n",
    "print(\"Current Configuration after initialization:\")\n",
    "print(f\"  model: {current.model}\")\n",
    "print(f\"  language: {current.language}\")\n",
    "print(f\"  batch_size: {current.batch_size}\")\n",
    "print(f\"  enable_vad: {current.enable_vad}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test configuration validation\n",
    "print(\"Configuration Validation Tests:\")\n",
    "\n",
    "# Valid config\n",
    "try:\n",
    "    plugin.initialize({\"model\": \"tiny\"})\n",
    "    print(\"✓ Valid config with model='tiny' accepted\")\n",
    "except ValueError as e:\n",
    "    print(f\"✗ Unexpected error: {e}\")\n",
    "\n",
    "# Invalid model name\n",
    "try:\n",
    "    plugin.initialize({\"model\": \"invalid_model\"})\n",
    "    print(\"✗ Should have rejected invalid model\")\n",
    "except ValueError as e:\n",
    "    print(f\"✓ Invalid model rejected: {e}\")\n",
    "\n",
    "# Batch size exceeds maximum\n",
    "try:\n",
    "    plugin.initialize({\"model\": \"base\", \"batch_size\": 100})\n",
    "    print(\"✗ Should have rejected batch_size > 32\")\n",
    "except ValueError as e:\n",
    "    print(f\"✓ Batch size > max rejected: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Whisper Plugin Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define comprehensive Whisper configuration dataclass\n",
    "@dataclass\n",
    "class WhisperPluginConfig:\n",
    "    \"\"\"Comprehensive configuration for Whisper transcription plugin.\"\"\"\n",
    "    model:str = field(\n",
    "        default=\"base\",\n",
    "        metadata={\n",
    "            SCHEMA_TITLE: \"Model\",\n",
    "            SCHEMA_DESC: \"Whisper model size. Larger models are more accurate but slower.\",\n",
    "            SCHEMA_ENUM: [\"tiny\", \"tiny.en\", \"base\", \"base.en\", \"small\", \"small.en\", \n",
    "                         \"medium\", \"medium.en\", \"large\", \"large-v1\", \"large-v2\", \"large-v3\"]\n",
    "        }\n",
    "    )\n",
    "    device:str = field(\n",
    "        default=\"auto\",\n",
    "        metadata={\n",
    "            SCHEMA_TITLE: \"Device\",\n",
    "            SCHEMA_DESC: \"Computation device for inference\",\n",
    "            SCHEMA_ENUM: [\"cpu\", \"cuda\", \"mps\", \"auto\"]\n",
    "        }\n",
    "    )\n",
    "    compute_type:str = field(\n",
    "        default=\"default\",\n",
    "        metadata={\n",
    "            SCHEMA_TITLE: \"Compute Type\",\n",
    "            SCHEMA_DESC: \"Model precision/quantization\",\n",
    "            SCHEMA_ENUM: [\"default\", \"float16\", \"float32\", \"int8\", \"int8_float16\"]\n",
    "        }\n",
    "    )\n",
    "    language:Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            SCHEMA_TITLE: \"Language\",\n",
    "            SCHEMA_DESC: \"Language code (e.g., 'en', 'es', 'fr') or None for auto-detection\"\n",
    "        }\n",
    "    )\n",
    "    task:str = field(\n",
    "        default=\"transcribe\",\n",
    "        metadata={\n",
    "            SCHEMA_TITLE: \"Task\",\n",
    "            SCHEMA_DESC: \"Task to perform\",\n",
    "            SCHEMA_ENUM: [\"transcribe\", \"translate\"]\n",
    "        }\n",
    "    )\n",
    "    temperature:float = field(\n",
    "        default=0.0,\n",
    "        metadata={\n",
    "            SCHEMA_TITLE: \"Temperature\",\n",
    "            SCHEMA_DESC: \"Sampling temperature. 0 for deterministic.\",\n",
    "            SCHEMA_MIN: 0.0,\n",
    "            SCHEMA_MAX: 1.0\n",
    "        }\n",
    "    )\n",
    "    beam_size:int = field(\n",
    "        default=5,\n",
    "        metadata={\n",
    "            SCHEMA_TITLE: \"Beam Size\",\n",
    "            SCHEMA_DESC: \"Beam search width.\",\n",
    "            SCHEMA_MIN: 1,\n",
    "            SCHEMA_MAX: 10\n",
    "        }\n",
    "    )\n",
    "    word_timestamps:bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            SCHEMA_TITLE: \"Word Timestamps\",\n",
    "            SCHEMA_DESC: \"Extract word-level timestamps\"\n",
    "        }\n",
    "    )\n",
    "    vad_filter:bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            SCHEMA_TITLE: \"VAD Filter\",\n",
    "            SCHEMA_DESC: \"Enable voice activity detection filter\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "class WhisperPlugin(TranscriptionPlugin):\n",
    "    \"\"\"Example Whisper transcription plugin with dataclass configuration.\"\"\"\n",
    "    \n",
    "    config_class = WhisperPluginConfig\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{type(self).__name__}\")\n",
    "        self.config: WhisperPluginConfig = None\n",
    "        self.model = None\n",
    "        self.processor = None\n",
    "    \n",
    "    @property\n",
    "    def name(self) -> str: # Plugin name identifier\n",
    "        return \"whisper\"\n",
    "    \n",
    "    @property\n",
    "    def version(self) -> str: # Plugin version string\n",
    "        return \"1.0.0\"\n",
    "    \n",
    "    @property\n",
    "    def supported_formats(self) -> List[str]: # List of supported audio file extensions\n",
    "        return [\"wav\", \"mp3\", \"flac\", \"m4a\", \"ogg\", \"webm\"]\n",
    "    \n",
    "    def get_current_config(self) -> WhisperPluginConfig: # Current configuration dataclass\n",
    "        \"\"\"Return current configuration.\"\"\"\n",
    "        return self.config\n",
    "    \n",
    "    def initialize(\n",
    "        self, \n",
    "        config: Optional[Any] = None # Configuration dataclass, dict, or None\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the Whisper model with configuration.\"\"\"\n",
    "        if config is None:\n",
    "            self.config = WhisperPluginConfig()\n",
    "        elif isinstance(config, WhisperPluginConfig):\n",
    "            self.config = config\n",
    "        elif isinstance(config, dict):\n",
    "            self.config = dict_to_config(WhisperPluginConfig, config, validate=True)\n",
    "        else:\n",
    "            raise TypeError(f\"Expected WhisperPluginConfig, dict, or None, got {type(config).__name__}\")\n",
    "        \n",
    "        self.logger.info(f\"Initializing Whisper with config: {self.config}\")\n",
    "        \n",
    "        # Mock implementation\n",
    "        self.model = f\"WhisperModel-{self.config.model}\"\n",
    "        self.processor = f\"WhisperProcessor-{self.config.device}\"\n",
    "    \n",
    "    def execute(\n",
    "        self,\n",
    "        audio: Union[AudioData, str, Path], # Audio data or path to audio file\n",
    "        **kwargs # Additional plugin-specific parameters\n",
    "    ) -> TranscriptionResult: # Transcription result with text, confidence, segments, and metadata\n",
    "        \"\"\"Transcribe audio using Whisper.\"\"\"\n",
    "        if not self.model:\n",
    "            raise RuntimeError(\"Plugin not initialized. Call initialize() first.\")\n",
    "        \n",
    "        self.logger.info(f\"Transcribing with Whisper model: {self.model}\")\n",
    "        \n",
    "        # Mock transcription result\n",
    "        return TranscriptionResult(\n",
    "            text=f\"Mock transcription using {self.config.model} model\",\n",
    "            confidence=0.95,\n",
    "            segments=[\n",
    "                {\"start\": 0.0, \"end\": 2.5, \"text\": \"Mock transcription\", \"confidence\": 0.96},\n",
    "                {\"start\": 2.5, \"end\": 5.0, \"text\": f\"using {self.config.model} model\", \"confidence\": 0.94}\n",
    "            ],\n",
    "            metadata={\n",
    "                \"model\": self.config.model,\n",
    "                \"language\": self.config.language or \"auto-detected\",\n",
    "                \"device\": self.config.device,\n",
    "                \"task\": self.config.task\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def is_available(self) -> bool: # True if Whisper dependencies are available\n",
    "        \"\"\"Check if Whisper dependencies are available.\"\"\"\n",
    "        return True  # Mock always available\n",
    "    \n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"Clean up model from memory.\"\"\"\n",
    "        self.logger.info(\"Cleaning up Whisper model\")\n",
    "        self.model = None\n",
    "        self.processor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__.WhisperPlugin:Initializing Whisper with config: WhisperPluginConfig(model='tiny', device='auto', compute_type='default', language=None, task='transcribe', temperature=0.0, beam_size=5, word_timestamps=False, vad_filter=False)\n",
      "INFO:__main__.WhisperPlugin:Transcribing with Whisper model: WhisperModel-tiny\n",
      "INFO:__main__.WhisperPlugin:Initializing Whisper with config: WhisperPluginConfig(model='large-v3', device='cuda', compute_type='default', language='en', task='transcribe', temperature=0.0, beam_size=5, word_timestamps=False, vad_filter=False)\n",
      "INFO:__main__.WhisperPlugin:Transcribing with Whisper model: WhisperModel-large-v3\n",
      "INFO:__main__.WhisperPlugin:Initializing Whisper with config: WhisperPluginConfig(model='base', device='auto', compute_type='default', language=None, task='transcribe', temperature=0.2, beam_size=3, word_timestamps=True, vad_filter=False)\n",
      "INFO:__main__.WhisperPlugin:Transcribing with Whisper model: WhisperModel-base\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper Configuration:\n",
      "Config class: WhisperPluginConfig\n",
      "Available models: ['tiny', 'tiny.en', 'base', 'base.en', 'small', 'small.en', 'medium', 'medium.en', 'large', 'large-v1', 'large-v2', 'large-v3']\n",
      "Available devices: ['cpu', 'cuda', 'mps', 'auto']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Initializing with config: {'model': 'tiny'}\n",
      "  model: tiny\n",
      "  device: auto\n",
      "  word_timestamps: False\n",
      "  Result: Mock transcription using tiny model\n",
      "------------------------------\n",
      "Initializing with config: {'model': 'large-v3', 'device': 'cuda', 'language': 'en'}\n",
      "  model: large-v3\n",
      "  device: cuda\n",
      "  word_timestamps: False\n",
      "  Result: Mock transcription using large-v3 model\n",
      "------------------------------\n",
      "Initializing with config: {'model': 'base', 'temperature': 0.2, 'beam_size': 3, 'word_timestamps': True}\n",
      "  model: base\n",
      "  device: auto\n",
      "  word_timestamps: True\n",
      "  Result: Mock transcription using base model\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the Whisper plugin with dataclass config\n",
    "whisper_plugin = WhisperPlugin()\n",
    "\n",
    "# Get config class info\n",
    "print(\"Whisper Configuration:\")\n",
    "print(f\"Config class: {whisper_plugin.config_class.__name__}\")\n",
    "print(f\"Available models: {WhisperPluginConfig.__dataclass_fields__['model'].metadata.get(SCHEMA_ENUM)}\")\n",
    "print(f\"Available devices: {WhisperPluginConfig.__dataclass_fields__['device'].metadata.get(SCHEMA_ENUM)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test initialization with different configurations\n",
    "configs_to_test = [\n",
    "    {\"model\": \"tiny\"},\n",
    "    {\"model\": \"large-v3\", \"device\": \"cuda\", \"language\": \"en\"},\n",
    "    {\"model\": \"base\", \"temperature\": 0.2, \"beam_size\": 3, \"word_timestamps\": True}\n",
    "]\n",
    "\n",
    "for config in configs_to_test:\n",
    "    print(f\"Initializing with config: {config}\")\n",
    "    whisper_plugin.initialize(config)\n",
    "    current = whisper_plugin.get_current_config()\n",
    "    print(f\"  model: {current.model}\")\n",
    "    print(f\"  device: {current.device}\")\n",
    "    print(f\"  word_timestamps: {current.word_timestamps}\")\n",
    "    \n",
    "    # Execute transcription\n",
    "    result = whisper_plugin.execute(\"dummy_audio.wav\")\n",
    "    print(f\"  Result: {result.text}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
