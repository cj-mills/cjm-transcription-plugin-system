{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription Plugin Interface\n",
    "\n",
    "> Domain-specific plugin interface for audio transcription plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp plugin_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "import logging\n",
    "from typing import Optional, Dict, Any, Union, List, Tuple, Generator\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Import generic plugin infrastructure from cjm-plugin-system\n",
    "from cjm_plugin_system.core.interface import PluginInterface\n",
    "from cjm_plugin_system.core.metadata import PluginMeta\n",
    "\n",
    "# Import domain-specific types\n",
    "from cjm_transcription_plugin_system.core import AudioData, TranscriptionResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TranscriptionPlugin(PluginInterface):\n",
    "    \"\"\"Transcription-specific plugin interface.\n",
    "    \n",
    "    This extends the generic PluginInterface with transcription-specific\n",
    "    requirements like supported audio formats and the execute signature.\n",
    "    \n",
    "    All transcription plugins must implement this interface.\n",
    "    \"\"\"\n",
    "\n",
    "    entry_point_group = \"transcription.plugins\"\n",
    "    \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def supported_formats(\n",
    "        self\n",
    "    ) -> List[str]:  # List of file extensions this plugin can process\n",
    "        \"\"\"List of supported audio formats (e.g., ['wav', 'mp3']).\n",
    "        \n",
    "        Returns:\n",
    "            List of file extensions without the dot (e.g., ['wav', 'mp3', 'flac'])\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def execute(\n",
    "        self,\n",
    "        audio: Union[AudioData, str, Path],  # Audio data or path to audio file\n",
    "        **kwargs  # Additional plugin-specific parameters\n",
    "    ) -> TranscriptionResult:  # Transcription result with text and metadata\n",
    "        \"\"\"Transcribe audio to text.\n",
    "        \n",
    "        Args:\n",
    "            audio: Audio data (AudioData object), file path (str), or Path object\n",
    "            **kwargs: Additional plugin-specific parameters (e.g., language, model)\n",
    "            \n",
    "        Returns:\n",
    "            TranscriptionResult containing transcribed text, confidence, segments, and metadata\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TranscriptionPlugin Interface\n",
    "\n",
    "The `TranscriptionPlugin` interface extends the generic `PluginInterface` from `cjm-plugin-system` with transcription-specific requirements:\n",
    "\n",
    "- **`supported_formats`** property: List of audio file formats this plugin can handle\n",
    "- **`execute`** method signature: Takes audio input and returns `TranscriptionResult`\n",
    "\n",
    "All generic plugin functionality (configuration management, validation, streaming support, etc.) is inherited from the base `PluginInterface` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PluginMeta instance:\n",
      "PluginMeta(name='test_plugin', version='1.0.0', description='A test plugin', author='Test Author', package_name='', instance=None, enabled=True)\n",
      "\n",
      "Name: test_plugin\n",
      "Version: 1.0.0\n",
      "Enabled: True\n",
      "Instance: None\n",
      "\n",
      "Minimal PluginMeta: PluginMeta(name='minimal', version='0.1.0', description='', author='', package_name='', instance=None, enabled=True)\n",
      "Equality test: True\n"
     ]
    }
   ],
   "source": [
    "# Test PluginMeta dataclass\n",
    "meta = PluginMeta(\n",
    "    name=\"test_plugin\",\n",
    "    version=\"1.0.0\",\n",
    "    description=\"A test plugin\",\n",
    "    author=\"Test Author\"\n",
    ")\n",
    "\n",
    "print(\"PluginMeta instance:\")\n",
    "print(meta)\n",
    "print(f\"\\nName: {meta.name}\")\n",
    "print(f\"Version: {meta.version}\")\n",
    "print(f\"Enabled: {meta.enabled}\")\n",
    "print(f\"Instance: {meta.instance}\")\n",
    "\n",
    "# Test with minimal arguments\n",
    "minimal_meta = PluginMeta(name=\"minimal\", version=\"0.1.0\")\n",
    "print(f\"\\nMinimal PluginMeta: {minimal_meta}\")\n",
    "\n",
    "# Test equality\n",
    "meta_copy = PluginMeta(name=\"minimal\", version=\"0.1.0\")\n",
    "print(f\"Equality test: {minimal_meta == meta_copy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ExamplePlugin\n",
    "\n",
    "Let's test a simple transcription plugin implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExamplePlugin(TranscriptionPlugin):\n",
    "    \"\"\"An example transcription plugin implementation with configuration schema.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{type(self).__name__}\")\n",
    "        self.config = {}\n",
    "        self.model = None\n",
    "    \n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"example_plugin\"\n",
    "    \n",
    "    @property\n",
    "    def version(self) -> str:\n",
    "        return \"1.0.0\"\n",
    "\n",
    "    @property\n",
    "    def supported_formats(self) -> List[str]:\n",
    "        return [\"wav\", \"mp3\", \"flac\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_config_schema() -> Dict[str, Any]:\n",
    "        \"\"\"Return the configuration schema for this plugin.\"\"\"\n",
    "        return {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"model\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"tiny\", \"base\", \"small\", \"medium\", \"large\"],\n",
    "                    \"default\": \"base\",\n",
    "                    \"description\": \"Model size to use for transcription\"\n",
    "                },\n",
    "                \"language\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"default\": \"auto\",\n",
    "                    \"description\": \"Language code (e.g., 'en', 'es') or 'auto' for detection\"\n",
    "                },\n",
    "                \"batch_size\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"minimum\": 1,\n",
    "                    \"maximum\": 32,\n",
    "                    \"default\": 8,\n",
    "                    \"description\": \"Batch size for processing\"\n",
    "                },\n",
    "                \"enable_vad\": {\n",
    "                    \"type\": \"boolean\",\n",
    "                    \"default\": True,\n",
    "                    \"description\": \"Enable voice activity detection\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"model\"]\n",
    "        }\n",
    "    \n",
    "    def get_current_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return the current configuration.\"\"\"\n",
    "        # Merge defaults with actual config\n",
    "        defaults = self.get_config_defaults()\n",
    "        return {**defaults, **self.config}\n",
    "    \n",
    "    def initialize(self, config: Optional[Dict[str, Any]] = None) -> None:\n",
    "        \"\"\"Initialize the plugin.\"\"\"\n",
    "        if config:\n",
    "            is_valid, error = self.validate_config(config)\n",
    "            if not is_valid:\n",
    "                raise ValueError(f\"Invalid configuration: {error}\")\n",
    "        \n",
    "        # Merge provided config with defaults\n",
    "        defaults = self.get_config_defaults()\n",
    "        self.config = {**defaults, **(config or {})}\n",
    "        \n",
    "        self.logger.info(f\"Initializing {self.name} with config: {self.config}\")\n",
    "        \n",
    "        # Simulate loading a model based on config\n",
    "        model_name = self.config.get(\"model\", \"base\")\n",
    "        self.model = f\"MockModel-{model_name}\"\n",
    "    \n",
    "    def execute(\n",
    "        self,\n",
    "        audio: Union[AudioData, str, Path],\n",
    "        **kwargs\n",
    "    ) -> TranscriptionResult:\n",
    "        \"\"\"Execute the plugin's functionality.\"\"\"\n",
    "        self.logger.info(f\"Example plugin executed with model: {self.model}\")\n",
    "        self.logger.info(f\"Config: {self.config}\")\n",
    "        \n",
    "        # Mock transcription result\n",
    "        return TranscriptionResult(\n",
    "            text=f\"Transcription using {self.model}\",\n",
    "            confidence=0.95,\n",
    "            segments=[],\n",
    "            metadata={\"model\": self.config.get(\"model\")}\n",
    "        )\n",
    "\n",
    "    def is_available(self) -> bool:\n",
    "        \"\"\"Check availability.\"\"\"\n",
    "        return True\n",
    "    \n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        self.logger.info(f\"Cleaning up {self.name}\")\n",
    "        self.model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__.ExamplePlugin:Initializing example_plugin with config: {'model': 'base', 'language': 'auto', 'batch_size': 8, 'enable_vad': True}\n",
      "INFO:__main__.ExamplePlugin:Example plugin executed with model: MockModel-base\n",
      "INFO:__main__.ExamplePlugin:Config: {'model': 'base', 'language': 'auto', 'batch_size': 8, 'enable_vad': True}\n",
      "INFO:__main__.ExamplePlugin:Cleaning up example_plugin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result text: Transcription using MockModel-base\n",
      "Result confidence: 0.95\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "example_plugin = ExamplePlugin()\n",
    "example_plugin.initialize()\n",
    "transcription_result = example_plugin.execute(\"test_audio.mp3\")\n",
    "example_plugin.cleanup()\n",
    "print(f\"Result text: {transcription_result.text}\")\n",
    "print(f\"Result confidence: {transcription_result.confidence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__.ExamplePlugin:Initializing example_plugin with config: {'model': 'small', 'language': 'en', 'batch_size': 8, 'enable_vad': True}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Schema:\n",
      "{\n",
      "  \"type\": \"object\",\n",
      "  \"properties\": {\n",
      "    \"model\": {\n",
      "      \"type\": \"string\",\n",
      "      \"enum\": [\n",
      "        \"tiny\",\n",
      "        \"base\",\n",
      "        \"small\",\n",
      "        \"medium\",\n",
      "        \"large\"\n",
      "      ],\n",
      "      \"default\": \"base\",\n",
      "      \"description\": \"Model size to use for transcription\"\n",
      "    },\n",
      "    \"language\": {\n",
      "      \"type\": \"string\",\n",
      "      \"default\": \"auto\",\n",
      "      \"description\": \"Language code (e.g., 'en', 'es') or 'auto' for detection\"\n",
      "    },\n",
      "    \"batch_size\": {\n",
      "      \"type\": \"integer\",\n",
      "      \"minimum\": 1,\n",
      "      \"maximum\": 32,\n",
      "      \"default\": 8,\n",
      "      \"description\": \"Batch size for processing\"\n",
      "    },\n",
      "    \"enable_vad\": {\n",
      "      \"type\": \"boolean\",\n",
      "      \"default\": true,\n",
      "      \"description\": \"Enable voice activity detection\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"model\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Default Configuration:\n",
      "{\n",
      "  \"model\": \"base\",\n",
      "  \"language\": \"auto\",\n",
      "  \"batch_size\": 8,\n",
      "  \"enable_vad\": true\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Current Configuration after initialization:\n",
      "{\n",
      "  \"model\": \"small\",\n",
      "  \"language\": \"en\",\n",
      "  \"batch_size\": 8,\n",
      "  \"enable_vad\": true\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Valid config with minimal settings:\n",
      "  Config: {'model': 'tiny'}\n",
      "  Valid: True\n",
      "\n",
      "Invalid model name:\n",
      "  Config: {'model': 'invalid_model'}\n",
      "  Valid: False\n",
      "  Error: 'invalid_model' is not one of ['tiny', 'base', 'small', 'medium', 'large']\n",
      "\n",
      "Fail...\n",
      "\n",
      "Missing required 'model' field:\n",
      "  Config: {'batch_size': 100}\n",
      "  Valid: False\n",
      "  Error: 'model' is a required property\n",
      "\n",
      "Failed validating 'required' in schema:\n",
      "    {'ty...\n",
      "\n",
      "Batch size exceeds maximum:\n",
      "  Config: {'model': 'base', 'batch_size': 100}\n",
      "  Valid: False\n",
      "  Error: 100 is greater than the maximum of 32\n",
      "\n",
      "Failed validating 'maximum' in schema['pr...\n",
      "\n",
      "Invalid type for batch_size:\n",
      "  Config: {'model': 'base', 'batch_size': 'not_a_number'}\n",
      "  Valid: False\n",
      "  Error: 'not_a_number' is not of type 'integer'\n",
      "\n",
      "Failed validating 'type' in schema['pro...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the configuration schema functionality\n",
    "plugin = ExamplePlugin()\n",
    "\n",
    "# Get the configuration schema\n",
    "schema = plugin.get_config_schema()\n",
    "print(\"Configuration Schema:\")\n",
    "print(json.dumps(schema, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Get default configuration\n",
    "defaults = plugin.get_config_defaults()\n",
    "print(\"Default Configuration:\")\n",
    "print(json.dumps(defaults, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Initialize with partial config (using defaults for missing values)\n",
    "plugin.initialize({\"model\": \"small\", \"language\": \"en\"})\n",
    "print(\"Current Configuration after initialization:\")\n",
    "print(json.dumps(plugin.get_current_config(), indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test configuration validation\n",
    "test_configs = [\n",
    "    ({\"model\": \"tiny\"}, \"Valid config with minimal settings\"),\n",
    "    ({\"model\": \"invalid_model\"}, \"Invalid model name\"),\n",
    "    ({\"batch_size\": 100}, \"Missing required 'model' field\"),\n",
    "    ({\"model\": \"base\", \"batch_size\": 100}, \"Batch size exceeds maximum\"),\n",
    "    ({\"model\": \"base\", \"batch_size\": \"not_a_number\"}, \"Invalid type for batch_size\"),\n",
    "]\n",
    "\n",
    "for config, description in test_configs:\n",
    "    is_valid, error = plugin.validate_config(config)\n",
    "    print(f\"{description}:\")\n",
    "    print(f\"  Config: {config}\")\n",
    "    print(f\"  Valid: {is_valid}\")\n",
    "    if error:\n",
    "        print(f\"  Error: {error[:80]}...\")  # Truncate long errors\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Whisper Plugin Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhisperPlugin(TranscriptionPlugin):\n",
    "    \"\"\"Example Whisper transcription plugin with comprehensive configuration.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{type(self).__name__}\")\n",
    "        self.config = {}\n",
    "        self.model = None\n",
    "        self.processor = None\n",
    "    \n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"whisper\"\n",
    "    \n",
    "    @property\n",
    "    def version(self) -> str:\n",
    "        return \"1.0.0\"\n",
    "    \n",
    "    @property\n",
    "    def supported_formats(self) -> List[str]:\n",
    "        return [\"wav\", \"mp3\", \"flac\", \"m4a\", \"ogg\", \"webm\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_config_schema() -> Dict[str, Any]:\n",
    "        \"\"\"Return comprehensive Whisper configuration schema.\"\"\"\n",
    "        return {\n",
    "            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "            \"type\": \"object\",\n",
    "            \"title\": \"Whisper Configuration\",\n",
    "            \"properties\": {\n",
    "                \"model\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"tiny\", \"tiny.en\", \"base\", \"base.en\", \"small\", \"small.en\", \n",
    "                            \"medium\", \"medium.en\", \"large\", \"large-v1\", \"large-v2\", \"large-v3\"],\n",
    "                    \"default\": \"base\",\n",
    "                    \"description\": \"Whisper model size. Larger models are more accurate but slower.\"\n",
    "                },\n",
    "                \"device\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"cpu\", \"cuda\", \"mps\", \"auto\"],\n",
    "                    \"default\": \"auto\",\n",
    "                    \"description\": \"Computation device for inference\"\n",
    "                },\n",
    "                \"compute_type\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"default\", \"float16\", \"float32\", \"int8\", \"int8_float16\"],\n",
    "                    \"default\": \"default\",\n",
    "                    \"description\": \"Model precision/quantization\"\n",
    "                },\n",
    "                \"language\": {\n",
    "                    \"type\": [\"string\", \"null\"],\n",
    "                    \"default\": None,\n",
    "                    \"description\": \"Language code (e.g., 'en', 'es', 'fr') or null for auto-detection\",\n",
    "                    \"examples\": [\"en\", \"es\", \"fr\", \"de\", \"ja\", \"zh\", None]\n",
    "                },\n",
    "                \"task\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"transcribe\", \"translate\"],\n",
    "                    \"default\": \"transcribe\",\n",
    "                    \"description\": \"Task to perform (transcribe keeps original language, translate converts to English)\"\n",
    "                },\n",
    "                \"temperature\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"minimum\": 0.0,\n",
    "                    \"maximum\": 1.0,\n",
    "                    \"default\": 0.0,\n",
    "                    \"description\": \"Sampling temperature. 0 for deterministic, higher values for more variation\"\n",
    "                },\n",
    "                \"beam_size\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"minimum\": 1,\n",
    "                    \"maximum\": 10,\n",
    "                    \"default\": 5,\n",
    "                    \"description\": \"Beam search width. Higher values may improve accuracy but are slower\"\n",
    "                },\n",
    "                \"best_of\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"minimum\": 1,\n",
    "                    \"maximum\": 10,\n",
    "                    \"default\": 5,\n",
    "                    \"description\": \"Number of candidates when sampling with non-zero temperature\"\n",
    "                },\n",
    "                \"patience\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"minimum\": 0.0,\n",
    "                    \"maximum\": 2.0,\n",
    "                    \"default\": 1.0,\n",
    "                    \"description\": \"Beam search patience factor\"\n",
    "                },\n",
    "                \"length_penalty\": {\n",
    "                    \"type\": [\"number\", \"null\"],\n",
    "                    \"default\": None,\n",
    "                    \"description\": \"Exponential length penalty during beam search\"\n",
    "                },\n",
    "                \"suppress_tokens\": {\n",
    "                    \"type\": [\"array\", \"string\"],\n",
    "                    \"items\": {\"type\": \"integer\"},\n",
    "                    \"default\": \"-1\",\n",
    "                    \"description\": \"Token IDs to suppress. '-1' for default suppression, empty array for none\"\n",
    "                },\n",
    "                \"initial_prompt\": {\n",
    "                    \"type\": [\"string\", \"null\"],\n",
    "                    \"default\": None,\n",
    "                    \"description\": \"Optional text to provide as prompt for first window\"\n",
    "                },\n",
    "                \"condition_on_previous_text\": {\n",
    "                    \"type\": \"boolean\",\n",
    "                    \"default\": True,\n",
    "                    \"description\": \"Use previous output as prompt for next window\"\n",
    "                },\n",
    "                \"no_speech_threshold\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"minimum\": 0.0,\n",
    "                    \"maximum\": 1.0,\n",
    "                    \"default\": 0.6,\n",
    "                    \"description\": \"Threshold for detecting silence\"\n",
    "                },\n",
    "                \"compression_ratio_threshold\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"minimum\": 1.0,\n",
    "                    \"maximum\": 10.0,\n",
    "                    \"default\": 2.4,\n",
    "                    \"description\": \"Threshold for detecting repetition\"\n",
    "                },\n",
    "                \"logprob_threshold\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"default\": -1.0,\n",
    "                    \"description\": \"Average log probability threshold\"\n",
    "                },\n",
    "                \"word_timestamps\": {\n",
    "                    \"type\": \"boolean\",\n",
    "                    \"default\": False,\n",
    "                    \"description\": \"Extract word-level timestamps\"\n",
    "                },\n",
    "                \"prepend_punctuations\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"default\": \"\\\"'“¿([{-\",\n",
    "                    \"description\": \"Punctuations to merge with next word\"\n",
    "                },\n",
    "                \"append_punctuations\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"default\": \"\\\"'.。,，!！?？:：”)]}、\",\n",
    "                    \"description\": \"Punctuations to merge with previous word\"\n",
    "                },\n",
    "                \"vad_filter\": {\n",
    "                    \"type\": \"boolean\",\n",
    "                    \"default\": False,\n",
    "                    \"description\": \"Enable voice activity detection filter\"\n",
    "                },\n",
    "                \"vad_parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"threshold\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"minimum\": 0.0,\n",
    "                            \"maximum\": 1.0,\n",
    "                            \"default\": 0.5\n",
    "                        },\n",
    "                        \"min_speech_duration_ms\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"minimum\": 0,\n",
    "                            \"default\": 250\n",
    "                        },\n",
    "                        \"max_speech_duration_s\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"minimum\": 0,\n",
    "                            \"default\": 3600\n",
    "                        }\n",
    "                    },\n",
    "                    \"default\": {}\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"model\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    \n",
    "    def get_current_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return current configuration with all defaults applied.\"\"\"\n",
    "        defaults = self.get_config_defaults()\n",
    "        current = {**defaults, **self.config}\n",
    "        \n",
    "        # Handle nested vad_parameters\n",
    "        if \"vad_parameters\" in current and isinstance(current[\"vad_parameters\"], dict):\n",
    "            vad_defaults = {\n",
    "                \"threshold\": 0.5,\n",
    "                \"min_speech_duration_ms\": 250,\n",
    "                \"max_speech_duration_s\": 3600\n",
    "            }\n",
    "            current[\"vad_parameters\"] = {**vad_defaults, **current[\"vad_parameters\"]}\n",
    "        \n",
    "        return current\n",
    "    \n",
    "    def initialize(self, config: Optional[Dict[str, Any]] = None) -> None:\n",
    "        \"\"\"Initialize the Whisper model with configuration.\"\"\"\n",
    "        if config:\n",
    "            is_valid, error = self.validate_config(config)\n",
    "            if not is_valid:\n",
    "                raise ValueError(f\"Invalid configuration: {error}\")\n",
    "        \n",
    "        # Merge with defaults\n",
    "        defaults = self.get_config_defaults()\n",
    "        self.config = {**defaults, **(config or {})}\n",
    "        \n",
    "        self.logger.info(f\"Initializing Whisper with config: {self.config}\")\n",
    "        \n",
    "        # In a real implementation, this would load the actual Whisper model\n",
    "        # For example:\n",
    "        # import whisper\n",
    "        # self.model = whisper.load_model(self.config[\"model\"], device=self.config[\"device\"])\n",
    "        \n",
    "        # Mock implementation\n",
    "        self.model = f\"WhisperModel-{self.config['model']}\"\n",
    "        self.processor = f\"WhisperProcessor-{self.config['device']}\"\n",
    "    \n",
    "    def execute(\n",
    "        self,\n",
    "        audio: Union[AudioData, str, Path],\n",
    "        **kwargs\n",
    "    ) -> TranscriptionResult:\n",
    "        \"\"\"Transcribe audio using Whisper.\"\"\"\n",
    "        if not self.model:\n",
    "            raise RuntimeError(\"Plugin not initialized. Call initialize() first.\")\n",
    "        \n",
    "        # Override config with any provided kwargs\n",
    "        exec_config = {**self.config, **kwargs}\n",
    "        \n",
    "        self.logger.info(f\"Transcribing with Whisper model: {self.model}\")\n",
    "        self.logger.info(f\"Execution config: {exec_config}\")\n",
    "        \n",
    "        # In a real implementation, this would:\n",
    "        # 1. Load/preprocess audio\n",
    "        # 2. Run Whisper inference\n",
    "        # 3. Post-process results\n",
    "        \n",
    "        # Mock transcription result\n",
    "        return TranscriptionResult(\n",
    "            text=f\"Mock transcription using {exec_config['model']} model\",\n",
    "            confidence=0.95,\n",
    "            segments=[\n",
    "                {\n",
    "                    \"start\": 0.0,\n",
    "                    \"end\": 2.5,\n",
    "                    \"text\": \"Mock transcription\",\n",
    "                    \"confidence\": 0.96\n",
    "                },\n",
    "                {\n",
    "                    \"start\": 2.5,\n",
    "                    \"end\": 5.0,\n",
    "                    \"text\": f\"using {exec_config['model']} model\",\n",
    "                    \"confidence\": 0.94\n",
    "                }\n",
    "            ],\n",
    "            metadata={\n",
    "                \"model\": exec_config[\"model\"],\n",
    "                \"language\": exec_config.get(\"language\", \"auto-detected\"),\n",
    "                \"device\": exec_config[\"device\"],\n",
    "                \"task\": exec_config[\"task\"]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def is_available(self) -> bool:\n",
    "        \"\"\"Check if Whisper dependencies are available.\"\"\"\n",
    "        try:\n",
    "            # In real implementation, check for whisper package\n",
    "            # import whisper\n",
    "            # return True\n",
    "            return True  # Mock always available\n",
    "        except ImportError:\n",
    "            return False\n",
    "    \n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"Clean up model from memory.\"\"\"\n",
    "        self.logger.info(\"Cleaning up Whisper model\")\n",
    "        self.model = None\n",
    "        self.processor = None\n",
    "        # In real implementation: del self.model, torch.cuda.empty_cache(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__.WhisperPlugin:Initializing Whisper with config: {'model': 'tiny', 'device': 'auto', 'compute_type': 'default', 'language': None, 'task': 'transcribe', 'temperature': 0.0, 'beam_size': 5, 'best_of': 5, 'patience': 1.0, 'length_penalty': None, 'suppress_tokens': '-1', 'initial_prompt': None, 'condition_on_previous_text': True, 'no_speech_threshold': 0.6, 'compression_ratio_threshold': 2.4, 'logprob_threshold': -1.0, 'word_timestamps': False, 'prepend_punctuations': '\"\\'“¿([{-', 'append_punctuations': '\"\\'.。,，!！?？:：”)]}、', 'vad_filter': False, 'vad_parameters': {}}\n",
      "INFO:__main__.WhisperPlugin:Transcribing with Whisper model: WhisperModel-tiny\n",
      "INFO:__main__.WhisperPlugin:Execution config: {'model': 'tiny', 'device': 'auto', 'compute_type': 'default', 'language': None, 'task': 'transcribe', 'temperature': 0.0, 'beam_size': 5, 'best_of': 5, 'patience': 1.0, 'length_penalty': None, 'suppress_tokens': '-1', 'initial_prompt': None, 'condition_on_previous_text': True, 'no_speech_threshold': 0.6, 'compression_ratio_threshold': 2.4, 'logprob_threshold': -1.0, 'word_timestamps': False, 'prepend_punctuations': '\"\\'“¿([{-', 'append_punctuations': '\"\\'.。,，!！?？:：”)]}、', 'vad_filter': False, 'vad_parameters': {}}\n",
      "INFO:__main__.WhisperPlugin:Initializing Whisper with config: {'model': 'large-v3', 'device': 'cuda', 'compute_type': 'default', 'language': 'en', 'task': 'transcribe', 'temperature': 0.0, 'beam_size': 5, 'best_of': 5, 'patience': 1.0, 'length_penalty': None, 'suppress_tokens': '-1', 'initial_prompt': None, 'condition_on_previous_text': True, 'no_speech_threshold': 0.6, 'compression_ratio_threshold': 2.4, 'logprob_threshold': -1.0, 'word_timestamps': False, 'prepend_punctuations': '\"\\'“¿([{-', 'append_punctuations': '\"\\'.。,，!！?？:：”)]}、', 'vad_filter': False, 'vad_parameters': {}}\n",
      "INFO:__main__.WhisperPlugin:Transcribing with Whisper model: WhisperModel-large-v3\n",
      "INFO:__main__.WhisperPlugin:Execution config: {'model': 'large-v3', 'device': 'cuda', 'compute_type': 'default', 'language': 'en', 'task': 'transcribe', 'temperature': 0.0, 'beam_size': 5, 'best_of': 5, 'patience': 1.0, 'length_penalty': None, 'suppress_tokens': '-1', 'initial_prompt': None, 'condition_on_previous_text': True, 'no_speech_threshold': 0.6, 'compression_ratio_threshold': 2.4, 'logprob_threshold': -1.0, 'word_timestamps': False, 'prepend_punctuations': '\"\\'“¿([{-', 'append_punctuations': '\"\\'.。,，!！?？:：”)]}、', 'vad_filter': False, 'vad_parameters': {}}\n",
      "INFO:__main__.WhisperPlugin:Initializing Whisper with config: {'model': 'base', 'device': 'auto', 'compute_type': 'default', 'language': None, 'task': 'transcribe', 'temperature': 0.2, 'beam_size': 3, 'best_of': 5, 'patience': 1.0, 'length_penalty': None, 'suppress_tokens': '-1', 'initial_prompt': None, 'condition_on_previous_text': True, 'no_speech_threshold': 0.6, 'compression_ratio_threshold': 2.4, 'logprob_threshold': -1.0, 'word_timestamps': True, 'prepend_punctuations': '\"\\'“¿([{-', 'append_punctuations': '\"\\'.。,，!！?？:：”)]}、', 'vad_filter': False, 'vad_parameters': {}}\n",
      "INFO:__main__.WhisperPlugin:Transcribing with Whisper model: WhisperModel-base\n",
      "INFO:__main__.WhisperPlugin:Execution config: {'model': 'base', 'device': 'auto', 'compute_type': 'default', 'language': None, 'task': 'transcribe', 'temperature': 0.2, 'beam_size': 3, 'best_of': 5, 'patience': 1.0, 'length_penalty': None, 'suppress_tokens': '-1', 'initial_prompt': None, 'condition_on_previous_text': True, 'no_speech_threshold': 0.6, 'compression_ratio_threshold': 2.4, 'logprob_threshold': -1.0, 'word_timestamps': True, 'prepend_punctuations': '\"\\'“¿([{-', 'append_punctuations': '\"\\'.。,，!！?？:：”)]}、', 'vad_filter': False, 'vad_parameters': {}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper Configuration Schema (subset):\n",
      "Available models: ['tiny', 'tiny.en', 'base', 'base.en', 'small', 'small.en', 'medium', 'medium.en', 'large', 'large-v1', 'large-v2', 'large-v3']\n",
      "Available devices: ['cpu', 'cuda', 'mps', 'auto']\n",
      "\n",
      "Required fields: ['model']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Initializing with config: {'model': 'tiny'}\n",
      "Current model: tiny\n",
      "Current device: auto\n",
      "Word timestamps: False\n",
      "Result: Mock transcription using tiny model\n",
      "------------------------------\n",
      "Initializing with config: {'model': 'large-v3', 'device': 'cuda', 'language': 'en'}\n",
      "Current model: large-v3\n",
      "Current device: cuda\n",
      "Word timestamps: False\n",
      "Result: Mock transcription using large-v3 model\n",
      "------------------------------\n",
      "Initializing with config: {'model': 'base', 'temperature': 0.2, 'beam_size': 3, 'word_timestamps': True}\n",
      "Current model: base\n",
      "Current device: auto\n",
      "Word timestamps: True\n",
      "Result: Mock transcription using base model\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the Whisper plugin\n",
    "whisper_plugin = WhisperPlugin()\n",
    "\n",
    "# Get a subset of the schema for display (it's quite large)\n",
    "schema = whisper_plugin.get_config_schema()\n",
    "print(\"Whisper Configuration Schema (subset):\")\n",
    "print(\"Available models:\", schema[\"properties\"][\"model\"][\"enum\"])\n",
    "print(\"Available devices:\", schema[\"properties\"][\"device\"][\"enum\"])\n",
    "print(\"\\nRequired fields:\", schema.get(\"required\", []))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test initialization with different configurations\n",
    "configs_to_test = [\n",
    "    {\"model\": \"tiny\"},\n",
    "    {\"model\": \"large-v3\", \"device\": \"cuda\", \"language\": \"en\"},\n",
    "    {\"model\": \"base\", \"temperature\": 0.2, \"beam_size\": 3, \"word_timestamps\": True}\n",
    "]\n",
    "\n",
    "for config in configs_to_test:\n",
    "    print(f\"Initializing with config: {config}\")\n",
    "    whisper_plugin.initialize(config)\n",
    "    current = whisper_plugin.get_current_config()\n",
    "    print(f\"Current model: {current['model']}\")\n",
    "    print(f\"Current device: {current['device']}\")\n",
    "    print(f\"Word timestamps: {current['word_timestamps']}\")\n",
    "    \n",
    "    # Execute transcription\n",
    "    result = whisper_plugin.execute(\"dummy_audio.wav\")\n",
    "    print(f\"Result: {result.text}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
