[
  {
    "objectID": "plugin_interface.html",
    "href": "plugin_interface.html",
    "title": "Transcription Plugin Interface",
    "section": "",
    "text": "source",
    "crumbs": [
      "Transcription Plugin Interface"
    ]
  },
  {
    "objectID": "plugin_interface.html#transcriptionplugin-interface",
    "href": "plugin_interface.html#transcriptionplugin-interface",
    "title": "Transcription Plugin Interface",
    "section": "TranscriptionPlugin Interface",
    "text": "TranscriptionPlugin Interface\nThe TranscriptionPlugin interface extends the generic PluginInterface from cjm-plugin-system with transcription-specific requirements:\n\nsupported_formats property: List of audio file formats this plugin can handle\nexecute method signature: Takes audio input and returns TranscriptionResult\n\nAll generic plugin functionality (configuration management, validation, streaming support, etc.) is inherited from the base PluginInterface class.\n\n# Test PluginMeta dataclass\nmeta = PluginMeta(\n    name=\"test_plugin\",\n    version=\"1.0.0\",\n    description=\"A test plugin\",\n    author=\"Test Author\"\n)\n\nprint(\"PluginMeta instance:\")\nprint(meta)\nprint(f\"\\nName: {meta.name}\")\nprint(f\"Version: {meta.version}\")\nprint(f\"Enabled: {meta.enabled}\")\nprint(f\"Instance: {meta.instance}\")\n\n# Test with minimal arguments\nminimal_meta = PluginMeta(name=\"minimal\", version=\"0.1.0\")\nprint(f\"\\nMinimal PluginMeta: {minimal_meta}\")\n\n# Test equality\nmeta_copy = PluginMeta(name=\"minimal\", version=\"0.1.0\")\nprint(f\"Equality test: {minimal_meta == meta_copy}\")\n\nPluginMeta instance:\nPluginMeta(name='test_plugin', version='1.0.0', description='A test plugin', author='Test Author', package_name='', instance=None, enabled=True)\n\nName: test_plugin\nVersion: 1.0.0\nEnabled: True\nInstance: None\n\nMinimal PluginMeta: PluginMeta(name='minimal', version='0.1.0', description='', author='', package_name='', instance=None, enabled=True)\nEquality test: True",
    "crumbs": [
      "Transcription Plugin Interface"
    ]
  },
  {
    "objectID": "plugin_interface.html#testing-exampleplugin",
    "href": "plugin_interface.html#testing-exampleplugin",
    "title": "Transcription Plugin Interface",
    "section": "Testing ExamplePlugin",
    "text": "Testing ExamplePlugin\nLet’s test a simple transcription plugin implementation.\n\nclass ExamplePlugin(TranscriptionPlugin):\n    \"\"\"An example transcription plugin implementation with configuration schema.\"\"\"\n\n    def __init__(self):\n        self.logger = logging.getLogger(f\"{__name__}.{type(self).__name__}\")\n        self.config = {}\n        self.model = None\n    \n    @property\n    def name(self) -&gt; str:  # Plugin name identifier\n        return \"example_plugin\"\n    \n    @property\n    def version(self) -&gt; str:  # Plugin version string\n        return \"1.0.0\"\n\n    @property\n    def supported_formats(self) -&gt; List[str]:  # List of supported audio file extensions\n        return [\"wav\", \"mp3\", \"flac\"]\n\n    @staticmethod\n    def get_config_schema() -&gt; Dict[str, Any]:  # JSON schema for plugin configuration\n        \"\"\"Return the configuration schema for this plugin.\"\"\"\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"model\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"tiny\", \"base\", \"small\", \"medium\", \"large\"],\n                    \"default\": \"base\",\n                    \"description\": \"Model size to use for transcription\"\n                },\n                \"language\": {\n                    \"type\": \"string\",\n                    \"default\": \"auto\",\n                    \"description\": \"Language code (e.g., 'en', 'es') or 'auto' for detection\"\n                },\n                \"batch_size\": {\n                    \"type\": \"integer\",\n                    \"minimum\": 1,\n                    \"maximum\": 32,\n                    \"default\": 8,\n                    \"description\": \"Batch size for processing\"\n                },\n                \"enable_vad\": {\n                    \"type\": \"boolean\",\n                    \"default\": True,\n                    \"description\": \"Enable voice activity detection\"\n                }\n            },\n            \"required\": [\"model\"]\n        }\n    \n    def get_current_config(self) -&gt; Dict[str, Any]:  # Current configuration with defaults merged\n        \"\"\"Return the current configuration.\"\"\"\n        # Merge defaults with actual config\n        defaults = self.get_config_defaults()\n        return {**defaults, **self.config}\n    \n    def initialize(\n        self, \n        config: Optional[Dict[str, Any]] = None  # Optional configuration dictionary\n    ) -&gt; None:\n        \"\"\"Initialize the plugin.\"\"\"\n        if config:\n            is_valid, error = self.validate_config(config)\n            if not is_valid:\n                raise ValueError(f\"Invalid configuration: {error}\")\n        \n        # Merge provided config with defaults\n        defaults = self.get_config_defaults()\n        self.config = {**defaults, **(config or {})}\n        \n        self.logger.info(f\"Initializing {self.name} with config: {self.config}\")\n        \n        # Simulate loading a model based on config\n        model_name = self.config.get(\"model\", \"base\")\n        self.model = f\"MockModel-{model_name}\"\n    \n    def execute(\n        self,\n        audio: Union[AudioData, str, Path],  # Audio data or path to audio file\n        **kwargs  # Additional plugin-specific parameters\n    ) -&gt; TranscriptionResult:  # Transcription result with text and metadata\n        \"\"\"Execute the plugin's functionality.\"\"\"\n        self.logger.info(f\"Example plugin executed with model: {self.model}\")\n        self.logger.info(f\"Config: {self.config}\")\n        \n        # Mock transcription result\n        return TranscriptionResult(\n            text=f\"Transcription using {self.model}\",\n            confidence=0.95,\n            segments=[],\n            metadata={\"model\": self.config.get(\"model\")}\n        )\n\n    def is_available(self) -&gt; bool:  # True if plugin dependencies are available\n        \"\"\"Check availability.\"\"\"\n        return True\n    \n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        self.logger.info(f\"Cleaning up {self.name}\")\n        self.model = None\n\n\nlogging.basicConfig(level=logging.INFO)\n\nexample_plugin = ExamplePlugin()\nexample_plugin.initialize()\ntranscription_result = example_plugin.execute(\"test_audio.mp3\")\nexample_plugin.cleanup()\nprint(f\"Result text: {transcription_result.text}\")\nprint(f\"Result confidence: {transcription_result.confidence}\")\n\nINFO:__main__.ExamplePlugin:Initializing example_plugin with config: {'model': 'base', 'language': 'auto', 'batch_size': 8, 'enable_vad': True}\nINFO:__main__.ExamplePlugin:Example plugin executed with model: MockModel-base\nINFO:__main__.ExamplePlugin:Config: {'model': 'base', 'language': 'auto', 'batch_size': 8, 'enable_vad': True}\nINFO:__main__.ExamplePlugin:Cleaning up example_plugin\n\n\nResult text: Transcription using MockModel-base\nResult confidence: 0.95\n\n\n\n# Test the configuration schema functionality\nplugin = ExamplePlugin()\n\n# Get the configuration schema\nschema = plugin.get_config_schema()\nprint(\"Configuration Schema:\")\nprint(json.dumps(schema, indent=2))\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# Get default configuration\ndefaults = plugin.get_config_defaults()\nprint(\"Default Configuration:\")\nprint(json.dumps(defaults, indent=2))\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# Initialize with partial config (using defaults for missing values)\nplugin.initialize({\"model\": \"small\", \"language\": \"en\"})\nprint(\"Current Configuration after initialization:\")\nprint(json.dumps(plugin.get_current_config(), indent=2))\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# Test configuration validation\ntest_configs = [\n    ({\"model\": \"tiny\"}, \"Valid config with minimal settings\"),\n    ({\"model\": \"invalid_model\"}, \"Invalid model name\"),\n    ({\"batch_size\": 100}, \"Missing required 'model' field\"),\n    ({\"model\": \"base\", \"batch_size\": 100}, \"Batch size exceeds maximum\"),\n    ({\"model\": \"base\", \"batch_size\": \"not_a_number\"}, \"Invalid type for batch_size\"),\n]\n\nfor config, description in test_configs:\n    is_valid, error = plugin.validate_config(config)\n    print(f\"{description}:\")\n    print(f\"  Config: {config}\")\n    print(f\"  Valid: {is_valid}\")\n    if error:\n        print(f\"  Error: {error[:80]}...\")  # Truncate long errors\n    print()\n\nINFO:__main__.ExamplePlugin:Initializing example_plugin with config: {'model': 'small', 'language': 'en', 'batch_size': 8, 'enable_vad': True}\n\n\nConfiguration Schema:\n{\n  \"type\": \"object\",\n  \"properties\": {\n    \"model\": {\n      \"type\": \"string\",\n      \"enum\": [\n        \"tiny\",\n        \"base\",\n        \"small\",\n        \"medium\",\n        \"large\"\n      ],\n      \"default\": \"base\",\n      \"description\": \"Model size to use for transcription\"\n    },\n    \"language\": {\n      \"type\": \"string\",\n      \"default\": \"auto\",\n      \"description\": \"Language code (e.g., 'en', 'es') or 'auto' for detection\"\n    },\n    \"batch_size\": {\n      \"type\": \"integer\",\n      \"minimum\": 1,\n      \"maximum\": 32,\n      \"default\": 8,\n      \"description\": \"Batch size for processing\"\n    },\n    \"enable_vad\": {\n      \"type\": \"boolean\",\n      \"default\": true,\n      \"description\": \"Enable voice activity detection\"\n    }\n  },\n  \"required\": [\n    \"model\"\n  ]\n}\n\n==================================================\n\nDefault Configuration:\n{\n  \"model\": \"base\",\n  \"language\": \"auto\",\n  \"batch_size\": 8,\n  \"enable_vad\": true\n}\n\n==================================================\n\nCurrent Configuration after initialization:\n{\n  \"model\": \"small\",\n  \"language\": \"en\",\n  \"batch_size\": 8,\n  \"enable_vad\": true\n}\n\n==================================================\n\nValid config with minimal settings:\n  Config: {'model': 'tiny'}\n  Valid: True\n\nInvalid model name:\n  Config: {'model': 'invalid_model'}\n  Valid: False\n  Error: 'invalid_model' is not one of ['tiny', 'base', 'small', 'medium', 'large']\n\nFail...\n\nMissing required 'model' field:\n  Config: {'batch_size': 100}\n  Valid: False\n  Error: 'model' is a required property\n\nFailed validating 'required' in schema:\n    {'ty...\n\nBatch size exceeds maximum:\n  Config: {'model': 'base', 'batch_size': 100}\n  Valid: False\n  Error: 100 is greater than the maximum of 32\n\nFailed validating 'maximum' in schema['pr...\n\nInvalid type for batch_size:\n  Config: {'model': 'base', 'batch_size': 'not_a_number'}\n  Valid: False\n  Error: 'not_a_number' is not of type 'integer'\n\nFailed validating 'type' in schema['pro...",
    "crumbs": [
      "Transcription Plugin Interface"
    ]
  },
  {
    "objectID": "plugin_interface.html#example-whisper-plugin-implementation",
    "href": "plugin_interface.html#example-whisper-plugin-implementation",
    "title": "Transcription Plugin Interface",
    "section": "Example: Whisper Plugin Implementation",
    "text": "Example: Whisper Plugin Implementation\n\nclass WhisperPlugin(TranscriptionPlugin):\n    \"\"\"Example Whisper transcription plugin with comprehensive configuration.\"\"\"\n    \n    def __init__(self):\n        self.logger = logging.getLogger(f\"{__name__}.{type(self).__name__}\")\n        self.config = {}\n        self.model = None\n        self.processor = None\n    \n    @property\n    def name(self) -&gt; str:  # Plugin name identifier\n        return \"whisper\"\n    \n    @property\n    def version(self) -&gt; str:  # Plugin version string\n        return \"1.0.0\"\n    \n    @property\n    def supported_formats(self) -&gt; List[str]:  # List of supported audio file extensions\n        return [\"wav\", \"mp3\", \"flac\", \"m4a\", \"ogg\", \"webm\"]\n\n    @staticmethod\n    def get_config_schema() -&gt; Dict[str, Any]:  # JSON schema for comprehensive Whisper configuration\n        \"\"\"Return comprehensive Whisper configuration schema.\"\"\"\n        return {\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n            \"type\": \"object\",\n            \"title\": \"Whisper Configuration\",\n            \"properties\": {\n                \"model\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"tiny\", \"tiny.en\", \"base\", \"base.en\", \"small\", \"small.en\", \n                            \"medium\", \"medium.en\", \"large\", \"large-v1\", \"large-v2\", \"large-v3\"],\n                    \"default\": \"base\",\n                    \"description\": \"Whisper model size. Larger models are more accurate but slower.\"\n                },\n                \"device\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"cpu\", \"cuda\", \"mps\", \"auto\"],\n                    \"default\": \"auto\",\n                    \"description\": \"Computation device for inference\"\n                },\n                \"compute_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"default\", \"float16\", \"float32\", \"int8\", \"int8_float16\"],\n                    \"default\": \"default\",\n                    \"description\": \"Model precision/quantization\"\n                },\n                \"language\": {\n                    \"type\": [\"string\", \"null\"],\n                    \"default\": None,\n                    \"description\": \"Language code (e.g., 'en', 'es', 'fr') or null for auto-detection\",\n                    \"examples\": [\"en\", \"es\", \"fr\", \"de\", \"ja\", \"zh\", None]\n                },\n                \"task\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"transcribe\", \"translate\"],\n                    \"default\": \"transcribe\",\n                    \"description\": \"Task to perform (transcribe keeps original language, translate converts to English)\"\n                },\n                \"temperature\": {\n                    \"type\": \"number\",\n                    \"minimum\": 0.0,\n                    \"maximum\": 1.0,\n                    \"default\": 0.0,\n                    \"description\": \"Sampling temperature. 0 for deterministic, higher values for more variation\"\n                },\n                \"beam_size\": {\n                    \"type\": \"integer\",\n                    \"minimum\": 1,\n                    \"maximum\": 10,\n                    \"default\": 5,\n                    \"description\": \"Beam search width. Higher values may improve accuracy but are slower\"\n                },\n                \"best_of\": {\n                    \"type\": \"integer\",\n                    \"minimum\": 1,\n                    \"maximum\": 10,\n                    \"default\": 5,\n                    \"description\": \"Number of candidates when sampling with non-zero temperature\"\n                },\n                \"patience\": {\n                    \"type\": \"number\",\n                    \"minimum\": 0.0,\n                    \"maximum\": 2.0,\n                    \"default\": 1.0,\n                    \"description\": \"Beam search patience factor\"\n                },\n                \"length_penalty\": {\n                    \"type\": [\"number\", \"null\"],\n                    \"default\": None,\n                    \"description\": \"Exponential length penalty during beam search\"\n                },\n                \"suppress_tokens\": {\n                    \"type\": [\"array\", \"string\"],\n                    \"items\": {\"type\": \"integer\"},\n                    \"default\": \"-1\",\n                    \"description\": \"Token IDs to suppress. '-1' for default suppression, empty array for none\"\n                },\n                \"initial_prompt\": {\n                    \"type\": [\"string\", \"null\"],\n                    \"default\": None,\n                    \"description\": \"Optional text to provide as prompt for first window\"\n                },\n                \"condition_on_previous_text\": {\n                    \"type\": \"boolean\",\n                    \"default\": True,\n                    \"description\": \"Use previous output as prompt for next window\"\n                },\n                \"no_speech_threshold\": {\n                    \"type\": \"number\",\n                    \"minimum\": 0.0,\n                    \"maximum\": 1.0,\n                    \"default\": 0.6,\n                    \"description\": \"Threshold for detecting silence\"\n                },\n                \"compression_ratio_threshold\": {\n                    \"type\": \"number\",\n                    \"minimum\": 1.0,\n                    \"maximum\": 10.0,\n                    \"default\": 2.4,\n                    \"description\": \"Threshold for detecting repetition\"\n                },\n                \"logprob_threshold\": {\n                    \"type\": \"number\",\n                    \"default\": -1.0,\n                    \"description\": \"Average log probability threshold\"\n                },\n                \"word_timestamps\": {\n                    \"type\": \"boolean\",\n                    \"default\": False,\n                    \"description\": \"Extract word-level timestamps\"\n                },\n                \"prepend_punctuations\": {\n                    \"type\": \"string\",\n                    \"default\": \"\\\"'“¿([{-\",\n                    \"description\": \"Punctuations to merge with next word\"\n                },\n                \"append_punctuations\": {\n                    \"type\": \"string\",\n                    \"default\": \"\\\"'.。,，!！?？:：”)]}、\",\n                    \"description\": \"Punctuations to merge with previous word\"\n                },\n                \"vad_filter\": {\n                    \"type\": \"boolean\",\n                    \"default\": False,\n                    \"description\": \"Enable voice activity detection filter\"\n                },\n                \"vad_parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"threshold\": {\n                            \"type\": \"number\",\n                            \"minimum\": 0.0,\n                            \"maximum\": 1.0,\n                            \"default\": 0.5\n                        },\n                        \"min_speech_duration_ms\": {\n                            \"type\": \"integer\",\n                            \"minimum\": 0,\n                            \"default\": 250\n                        },\n                        \"max_speech_duration_s\": {\n                            \"type\": \"number\",\n                            \"minimum\": 0,\n                            \"default\": 3600\n                        }\n                    },\n                    \"default\": {}\n                }\n            },\n            \"required\": [\"model\"],\n            \"additionalProperties\": False\n        }\n    \n    def get_current_config(self) -&gt; Dict[str, Any]:  # Current configuration with all defaults applied\n        \"\"\"Return current configuration with all defaults applied.\"\"\"\n        defaults = self.get_config_defaults()\n        current = {**defaults, **self.config}\n        \n        # Handle nested vad_parameters\n        if \"vad_parameters\" in current and isinstance(current[\"vad_parameters\"], dict):\n            vad_defaults = {\n                \"threshold\": 0.5,\n                \"min_speech_duration_ms\": 250,\n                \"max_speech_duration_s\": 3600\n            }\n            current[\"vad_parameters\"] = {**vad_defaults, **current[\"vad_parameters\"]}\n        \n        return current\n    \n    def initialize(\n        self, \n        config: Optional[Dict[str, Any]] = None  # Optional configuration dictionary\n    ) -&gt; None:\n        \"\"\"Initialize the Whisper model with configuration.\"\"\"\n        if config:\n            is_valid, error = self.validate_config(config)\n            if not is_valid:\n                raise ValueError(f\"Invalid configuration: {error}\")\n        \n        # Merge with defaults\n        defaults = self.get_config_defaults()\n        self.config = {**defaults, **(config or {})}\n        \n        self.logger.info(f\"Initializing Whisper with config: {self.config}\")\n        \n        # In a real implementation, this would load the actual Whisper model\n        # For example:\n        # import whisper\n        # self.model = whisper.load_model(self.config[\"model\"], device=self.config[\"device\"])\n        \n        # Mock implementation\n        self.model = f\"WhisperModel-{self.config['model']}\"\n        self.processor = f\"WhisperProcessor-{self.config['device']}\"\n    \n    def execute(\n        self,\n        audio: Union[AudioData, str, Path],  # Audio data or path to audio file\n        **kwargs  # Additional plugin-specific parameters\n    ) -&gt; TranscriptionResult:  # Transcription result with text, confidence, segments, and metadata\n        \"\"\"Transcribe audio using Whisper.\"\"\"\n        if not self.model:\n            raise RuntimeError(\"Plugin not initialized. Call initialize() first.\")\n        \n        # Override config with any provided kwargs\n        exec_config = {**self.config, **kwargs}\n        \n        self.logger.info(f\"Transcribing with Whisper model: {self.model}\")\n        self.logger.info(f\"Execution config: {exec_config}\")\n        \n        # In a real implementation, this would:\n        # 1. Load/preprocess audio\n        # 2. Run Whisper inference\n        # 3. Post-process results\n        \n        # Mock transcription result\n        return TranscriptionResult(\n            text=f\"Mock transcription using {exec_config['model']} model\",\n            confidence=0.95,\n            segments=[\n                {\n                    \"start\": 0.0,\n                    \"end\": 2.5,\n                    \"text\": \"Mock transcription\",\n                    \"confidence\": 0.96\n                },\n                {\n                    \"start\": 2.5,\n                    \"end\": 5.0,\n                    \"text\": f\"using {exec_config['model']} model\",\n                    \"confidence\": 0.94\n                }\n            ],\n            metadata={\n                \"model\": exec_config[\"model\"],\n                \"language\": exec_config.get(\"language\", \"auto-detected\"),\n                \"device\": exec_config[\"device\"],\n                \"task\": exec_config[\"task\"]\n            }\n        )\n    \n    def is_available(self) -&gt; bool:  # True if Whisper dependencies are available\n        \"\"\"Check if Whisper dependencies are available.\"\"\"\n        try:\n            # In real implementation, check for whisper package\n            # import whisper\n            # return True\n            return True  # Mock always available\n        except ImportError:\n            return False\n    \n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up model from memory.\"\"\"\n        self.logger.info(\"Cleaning up Whisper model\")\n        self.model = None\n        self.processor = None\n        # In real implementation: del self.model, torch.cuda.empty_cache(), etc.\n\n\n# Test the Whisper plugin\nwhisper_plugin = WhisperPlugin()\n\n# Get a subset of the schema for display (it's quite large)\nschema = whisper_plugin.get_config_schema()\nprint(\"Whisper Configuration Schema (subset):\")\nprint(\"Available models:\", schema[\"properties\"][\"model\"][\"enum\"])\nprint(\"Available devices:\", schema[\"properties\"][\"device\"][\"enum\"])\nprint(\"\\nRequired fields:\", schema.get(\"required\", []))\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# Test initialization with different configurations\nconfigs_to_test = [\n    {\"model\": \"tiny\"},\n    {\"model\": \"large-v3\", \"device\": \"cuda\", \"language\": \"en\"},\n    {\"model\": \"base\", \"temperature\": 0.2, \"beam_size\": 3, \"word_timestamps\": True}\n]\n\nfor config in configs_to_test:\n    print(f\"Initializing with config: {config}\")\n    whisper_plugin.initialize(config)\n    current = whisper_plugin.get_current_config()\n    print(f\"Current model: {current['model']}\")\n    print(f\"Current device: {current['device']}\")\n    print(f\"Word timestamps: {current['word_timestamps']}\")\n    \n    # Execute transcription\n    result = whisper_plugin.execute(\"dummy_audio.wav\")\n    print(f\"Result: {result.text}\")\n    print(\"-\" * 30)\n\nINFO:__main__.WhisperPlugin:Initializing Whisper with config: {'model': 'tiny', 'device': 'auto', 'compute_type': 'default', 'language': None, 'task': 'transcribe', 'temperature': 0.0, 'beam_size': 5, 'best_of': 5, 'patience': 1.0, 'length_penalty': None, 'suppress_tokens': '-1', 'initial_prompt': None, 'condition_on_previous_text': True, 'no_speech_threshold': 0.6, 'compression_ratio_threshold': 2.4, 'logprob_threshold': -1.0, 'word_timestamps': False, 'prepend_punctuations': '\"\\'“¿([{-', 'append_punctuations': '\"\\'.。,，!！?？:：”)]}、', 'vad_filter': False, 'vad_parameters': {}}\nINFO:__main__.WhisperPlugin:Transcribing with Whisper model: WhisperModel-tiny\nINFO:__main__.WhisperPlugin:Execution config: {'model': 'tiny', 'device': 'auto', 'compute_type': 'default', 'language': None, 'task': 'transcribe', 'temperature': 0.0, 'beam_size': 5, 'best_of': 5, 'patience': 1.0, 'length_penalty': None, 'suppress_tokens': '-1', 'initial_prompt': None, 'condition_on_previous_text': True, 'no_speech_threshold': 0.6, 'compression_ratio_threshold': 2.4, 'logprob_threshold': -1.0, 'word_timestamps': False, 'prepend_punctuations': '\"\\'“¿([{-', 'append_punctuations': '\"\\'.。,，!！?？:：”)]}、', 'vad_filter': False, 'vad_parameters': {}}\nINFO:__main__.WhisperPlugin:Initializing Whisper with config: {'model': 'large-v3', 'device': 'cuda', 'compute_type': 'default', 'language': 'en', 'task': 'transcribe', 'temperature': 0.0, 'beam_size': 5, 'best_of': 5, 'patience': 1.0, 'length_penalty': None, 'suppress_tokens': '-1', 'initial_prompt': None, 'condition_on_previous_text': True, 'no_speech_threshold': 0.6, 'compression_ratio_threshold': 2.4, 'logprob_threshold': -1.0, 'word_timestamps': False, 'prepend_punctuations': '\"\\'“¿([{-', 'append_punctuations': '\"\\'.。,，!！?？:：”)]}、', 'vad_filter': False, 'vad_parameters': {}}\nINFO:__main__.WhisperPlugin:Transcribing with Whisper model: WhisperModel-large-v3\nINFO:__main__.WhisperPlugin:Execution config: {'model': 'large-v3', 'device': 'cuda', 'compute_type': 'default', 'language': 'en', 'task': 'transcribe', 'temperature': 0.0, 'beam_size': 5, 'best_of': 5, 'patience': 1.0, 'length_penalty': None, 'suppress_tokens': '-1', 'initial_prompt': None, 'condition_on_previous_text': True, 'no_speech_threshold': 0.6, 'compression_ratio_threshold': 2.4, 'logprob_threshold': -1.0, 'word_timestamps': False, 'prepend_punctuations': '\"\\'“¿([{-', 'append_punctuations': '\"\\'.。,，!！?？:：”)]}、', 'vad_filter': False, 'vad_parameters': {}}\nINFO:__main__.WhisperPlugin:Initializing Whisper with config: {'model': 'base', 'device': 'auto', 'compute_type': 'default', 'language': None, 'task': 'transcribe', 'temperature': 0.2, 'beam_size': 3, 'best_of': 5, 'patience': 1.0, 'length_penalty': None, 'suppress_tokens': '-1', 'initial_prompt': None, 'condition_on_previous_text': True, 'no_speech_threshold': 0.6, 'compression_ratio_threshold': 2.4, 'logprob_threshold': -1.0, 'word_timestamps': True, 'prepend_punctuations': '\"\\'“¿([{-', 'append_punctuations': '\"\\'.。,，!！?？:：”)]}、', 'vad_filter': False, 'vad_parameters': {}}\nINFO:__main__.WhisperPlugin:Transcribing with Whisper model: WhisperModel-base\nINFO:__main__.WhisperPlugin:Execution config: {'model': 'base', 'device': 'auto', 'compute_type': 'default', 'language': None, 'task': 'transcribe', 'temperature': 0.2, 'beam_size': 3, 'best_of': 5, 'patience': 1.0, 'length_penalty': None, 'suppress_tokens': '-1', 'initial_prompt': None, 'condition_on_previous_text': True, 'no_speech_threshold': 0.6, 'compression_ratio_threshold': 2.4, 'logprob_threshold': -1.0, 'word_timestamps': True, 'prepend_punctuations': '\"\\'“¿([{-', 'append_punctuations': '\"\\'.。,，!！?？:：”)]}、', 'vad_filter': False, 'vad_parameters': {}}\n\n\nWhisper Configuration Schema (subset):\nAvailable models: ['tiny', 'tiny.en', 'base', 'base.en', 'small', 'small.en', 'medium', 'medium.en', 'large', 'large-v1', 'large-v2', 'large-v3']\nAvailable devices: ['cpu', 'cuda', 'mps', 'auto']\n\nRequired fields: ['model']\n\n==================================================\n\nInitializing with config: {'model': 'tiny'}\nCurrent model: tiny\nCurrent device: auto\nWord timestamps: False\nResult: Mock transcription using tiny model\n------------------------------\nInitializing with config: {'model': 'large-v3', 'device': 'cuda', 'language': 'en'}\nCurrent model: large-v3\nCurrent device: cuda\nWord timestamps: False\nResult: Mock transcription using large-v3 model\n------------------------------\nInitializing with config: {'model': 'base', 'temperature': 0.2, 'beam_size': 3, 'word_timestamps': True}\nCurrent model: base\nCurrent device: auto\nWord timestamps: True\nResult: Mock transcription using base model\n------------------------------",
    "crumbs": [
      "Transcription Plugin Interface"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#testing-the-dataclasses",
    "href": "core.html#testing-the-dataclasses",
    "title": "core",
    "section": "Testing the dataclasses",
    "text": "Testing the dataclasses\n\n# Test AudioData\nimport numpy as np\n\naudio = AudioData(\n    samples=np.array([0.1, 0.2, 0.3]),\n    sample_rate=16000,\n    duration=1.5,\n    filepath=Path(\"/tmp/test.wav\")\n)\n\nprint(\"AudioData instance:\")\nprint(audio)\nprint(f\"\\nMetadata: {audio.metadata}\")\naudio.metadata['format'] = 'wav'\nprint(f\"Updated metadata: {audio.metadata}\")\n\nAudioData instance:\nAudioData(samples=array([0.1, 0.2, 0.3]), sample_rate=16000, duration=1.5, filepath=Path('/tmp/test.wav'), metadata={})\n\nMetadata: {}\nUpdated metadata: {'format': 'wav'}\n\n\n\n# Test TranscriptionResult\nresult = TranscriptionResult(\n    text=\"Hello world\",\n    confidence=0.95,\n    segments=[\n        {\"start\": 0.0, \"end\": 0.5, \"text\": \"Hello\"},\n        {\"start\": 0.5, \"end\": 1.0, \"text\": \"world\"}\n    ]\n)\n\nprint(\"TranscriptionResult instance:\")\nprint(result)\nprint(f\"\\nText: {result.text}\")\nprint(f\"Confidence: {result.confidence}\")\nprint(f\"Segments: {result.segments}\")\nprint(f\"Metadata: {result.metadata}\")\n\nTranscriptionResult instance:\nTranscriptionResult(text='Hello world', confidence=0.95, segments=[{'start': 0.0, 'end': 0.5, 'text': 'Hello'}, {'start': 0.5, 'end': 1.0, 'text': 'world'}], metadata={})\n\nText: Hello world\nConfidence: 0.95\nSegments: [{'start': 0.0, 'end': 0.5, 'text': 'Hello'}, {'start': 0.5, 'end': 1.0, 'text': 'world'}]\nMetadata: {}\n\n\n\n# Test default values\nresult_minimal = TranscriptionResult(text=\"Just text\")\nprint(\"\\nMinimal TranscriptionResult:\")\nprint(f\"Text: {result_minimal.text}\")\nprint(f\"Confidence: {result_minimal.confidence}\")\nprint(f\"Segments: {result_minimal.segments}\")\nprint(f\"Metadata: {result_minimal.metadata}\")\n\n# Test equality (automatic with dataclass)\nresult_copy = TranscriptionResult(text=\"Just text\")\nprint(f\"\\nEquality test: {result_minimal == result_copy}\")\n\n\nMinimal TranscriptionResult:\nText: Just text\nConfidence: None\nSegments: []\nMetadata: {}\n\nEquality test: True",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "cjm-transcription-plugin-system",
    "section": "",
    "text": "pip install cjm_transcription_plugin_system",
    "crumbs": [
      "cjm-transcription-plugin-system"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "cjm-transcription-plugin-system",
    "section": "",
    "text": "pip install cjm_transcription_plugin_system",
    "crumbs": [
      "cjm-transcription-plugin-system"
    ]
  },
  {
    "objectID": "index.html#project-structure",
    "href": "index.html#project-structure",
    "title": "cjm-transcription-plugin-system",
    "section": "Project Structure",
    "text": "Project Structure\nnbs/\n├── core.ipynb             # Core data structures for audio transcription\n└── plugin_interface.ipynb # Domain-specific plugin interface for audio transcription plugins\nTotal: 2 notebooks",
    "crumbs": [
      "cjm-transcription-plugin-system"
    ]
  },
  {
    "objectID": "index.html#module-dependencies",
    "href": "index.html#module-dependencies",
    "title": "cjm-transcription-plugin-system",
    "section": "Module Dependencies",
    "text": "Module Dependencies\ngraph LR\n    core[core&lt;br/&gt;core]\n    plugin_interface[plugin_interface&lt;br/&gt;Transcription Plugin Interface]\n\n    plugin_interface --&gt; core\n1 cross-module dependencies detected",
    "crumbs": [
      "cjm-transcription-plugin-system"
    ]
  },
  {
    "objectID": "index.html#cli-reference",
    "href": "index.html#cli-reference",
    "title": "cjm-transcription-plugin-system",
    "section": "CLI Reference",
    "text": "CLI Reference\nNo CLI commands found in this project.",
    "crumbs": [
      "cjm-transcription-plugin-system"
    ]
  },
  {
    "objectID": "index.html#module-overview",
    "href": "index.html#module-overview",
    "title": "cjm-transcription-plugin-system",
    "section": "Module Overview",
    "text": "Module Overview\nDetailed documentation for each module in the project:\n\ncore (core.ipynb)\n\nCore data structures for audio transcription\n\n\nImport\nfrom cjm_transcription_plugin_system.core import (\n    AudioData,\n    TranscriptionResult\n)\n\n\nClasses\n@dataclass\nclass AudioData:\n    \"Container for audio data and metadata.\"\n    \n    samples: np.ndarray  # Audio sample data as a numpy array\n    sample_rate: int  # Sample rate in Hz (e.g., 16000, 44100)\n    duration: float  # Duration of the audio in seconds\n    filepath: Optional[Path]  # Audio file path\n    metadata: Dict[str, Any] = field(...)  # Additional metadata\n@dataclass\nclass TranscriptionResult:\n    \"Standardized transcription output.\"\n    \n    text: str  # The transcribed text\n    confidence: Optional[float]  # Overall confidence score (0.0 to 1.0)\n    segments: Optional[List[Dict]] = field(...)  # List of transcription segments with timestamps and text\n    metadata: Optional[Dict] = field(...)  # Transcription metadata\n\n\n\nTranscription Plugin Interface (plugin_interface.ipynb)\n\nDomain-specific plugin interface for audio transcription plugins\n\n\nImport\nfrom cjm_transcription_plugin_system.plugin_interface import (\n    TranscriptionPlugin\n)\n\n\nClasses\nclass TranscriptionPlugin(PluginInterface):\n    \"\"\"\n    Transcription-specific plugin interface.\n    \n    This extends the generic PluginInterface with transcription-specific\n    requirements like supported audio formats and the execute signature.\n    \n    All transcription plugins must implement this interface.\n    \"\"\"\n    \n    def supported_formats(\n            self\n        ) -&gt; List[str]:  # List of file extensions without the dot (e.g., ['wav', 'mp3', 'flac'])\n        \"List of supported audio formats.\"\n    \n    def execute(\n            self,\n            audio: Union[AudioData, str, Path],  # Audio data (AudioData object), file path (str), or Path object\n            **kwargs  # Additional plugin-specific parameters (e.g., language, model)\n        ) -&gt; TranscriptionResult:  # Transcription result with text, confidence, segments, and metadata\n        \"Transcribe audio to text.\"",
    "crumbs": [
      "cjm-transcription-plugin-system"
    ]
  }
]